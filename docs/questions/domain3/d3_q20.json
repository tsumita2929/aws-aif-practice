{
  "id": "d3_q20",
  "type": "single",
  "text": "AIガバナンスフレームワークに含まれるべき要素として適切でないものはどれですか？",
  "choices": [
    {
      "label": "A",
      "text": "リスク評価プロセス"
    },
    {
      "label": "B",
      "text": "倫理委員会の設置"
    },
    {
      "label": "C",
      "text": "監査とモニタリング体制"
    },
    {
      "label": "D",
      "text": "利益最大化のみを目的とした意思決定"
    }
  ],
  "correct": [
    3
  ],
  "explanation": "<h5>詳細解説</h5><p>正解はD「利益最大化のみを目的とした意思決定」です。</p><p>AIガバナンスフレームワークは、AIの開発と運用を倫理的かつ責任ある方法で行うための包括的な枠組みです。利益最大化のみを追求することは、倫理的な考慮や社会的責任を無視することにつながり、適切なガバナンスとは相反します。</p><h5>適切なAIガバナンスフレームワークの要素</h5><ul><li><strong>A「リスク評価プロセス」:</strong> AIシステムがもたらす潜在的なリスクを特定し、評価し、軽減するための体系的なプロセス</li><li><strong>B「倫理委員会の設置」:</strong> AI開発と運用に関する倫理的な問題を検討し、指針を提供する独立した委員会</li><li><strong>C「監査とモニタリング体制」:</strong> AIシステムの性能、公平性、安全性を継続的に監視し、問題を早期に発見する仕組み</li></ul><h5>その他の重要な要素</h5><ul><li>明確な責任体制とアカウンタビリティ</li><li>ステークホルダーエンゲージメント</li><li>透明性とコミュニケーション方針</li><li>継続的な改善プロセス</li><li>規制準拠の確保</li></ul><p>健全なAIガバナンスは、短期的な利益だけでなく、長期的な持続可能性、社会的価値、ステークホルダーの利益のバランスを考慮する必要があります。</p><h5>なぜ他の選択肢が間違っているのか</h5><ul><li><strong>A) リスク評価プロセス:</strong> AIシステムがもたらす潜在的なリスクを特定し、評価し、軽減するための体系的なプロセス</li><li><strong>B) 倫理委員会の設置:</strong> AI開発と運用に関する倫理的な問題を検討し、指針を提供する独立した委員会</li><li><strong>C) 監査とモニタリング体制:</strong> AIシステムの性能、公平性、安全性を継続的に監視し、問題を早期に発見する仕組み</li></ul>",
  "resources": []
}
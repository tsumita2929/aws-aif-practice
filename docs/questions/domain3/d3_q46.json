{
  "id": "d3_q46",
  "type": "single",
  "text": "生成AIモデルの「ハルシネーション」（幻覚）を軽減するための最も効果的なアプローチはどれですか？",
  "choices": [
    {
      "label": "A",
      "text": "より大きなモデルを使用する"
    },
    {
      "label": "B",
      "text": "RAGアーキテクチャと事実確認メカニズムの実装"
    },
    {
      "label": "C",
      "text": "プロンプトを短くする"
    },
    {
      "label": "D",
      "text": "出力の文字数を制限する"
    }
  ],
  "correct": [
    1
  ],
  "explanation": "正解はB「RAGアーキテクチャと事実確認メカニズムの実装」です。\n\n生成AIモデルの「ハルシネーション」（幻覚）は、モデルが事実と異なる情報や存在しない情報を生成する現象で、生成AIの信頼性における重大な課題です。\n\nRAG（Retrieval-Augmented Generation）アーキテクチャと事実確認メカニズムが効果的な理由：\n\n1. RAGアーキテクチャの利点：\n- 外部知識ベースからの情報検索により、事実に基づいた生成が可能\n- 最新情報へのアクセスによる時代遅れの情報の回避\n- ソース情報の追跡可能性\n- ドメイン特化型知識の活用\n\n2. 事実確認メカニズム：\n- 生成された内容の検証プロセス\n- 信頼できるソースとの照合\n- 矛盾検出システム\n- 信頼度スコアの算出\n\n3. 実装方法：\n- ベクトルデータベースの活用\n- 知識グラフとの統合\n- マルチステップ検証\n- ヒューマン・イン・ザ・ループの組み込み\n\n他の選択肢が不適切な理由：\n- A「より大きなモデルを使用する」：モデルサイズの増加だけではハルシネーションを根本的に解決できません。\n- C「プロンプトを短くする」：プロンプトの長さとハルシネーションの発生に直接的な相関はありません。\n- D「出力の文字数を制限する」：出力量の制限は問題の回避であり、解決ではありません。\n\nハルシネーションの軽減は、技術的対策と運用上の工夫の組み合わせが重要です。",
  "resources": []
}
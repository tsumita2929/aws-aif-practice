{
  "id": "d3_q22",
  "type": "single",
  "text": "次のシナリオを考えてください： 「教育機関が学生の成績予測AIを導入したが、社会経済的背景による偏りが懸念される」 適切な対応策はどれですか？",
  "choices": [
    {
      "label": "A",
      "text": "社会経済的データを完全に除外する"
    },
    {
      "label": "B",
      "text": "公平性制約を加えたモデルの再設計と継続的なモニタリング"
    },
    {
      "label": "C",
      "text": "AIの使用を中止する"
    },
    {
      "label": "D",
      "text": "予測結果を隠す"
    }
  ],
  "correct": [
    1
  ],
  "explanation": "<h5>詳細解説</h5><p>正解はB「公平性制約を加えたモデルの再設計と継続的なモニタリング」です。</p><p>教育機関における成績予測AIで社会経済的背景による偏りが懸念される場合、問題を認識し、積極的に対処することが重要です。単に問題を無視したり、システムを放棄したりするのではなく、公平性を確保しながらAIの利点を活かす方法を追求すべきです。</p><h5>適切な対応策の内容</h5><ul><li>公平性制約の実装：異なる社会経済的グループ間で予測精度が均等になるようモデルを調整</li><li>バイアス検出：定期的にモデルの予測結果を分析し、偏りを特定</li><li>継続的モニタリング：デプロイ後も公平性指標を監視し、問題を早期発見</li><li>多様なステークホルダーの関与：学生、教員、保護者の意見を反映</li><li>補完的な支援策：AIの予測に基づいて、不利な立場の学生への追加支援を提供</li></ul><h5>なぜ他の選択肢が間違っているのか</h5><ul><li><strong>A) 社会経済的データを完全に除外する:</strong> データを除外しても、他の変数（住所、学校名など）が代理変数となり、間接的な差別が続く可能性があります。</li><li><strong>C) AIの使用を中止する:</strong> AIの利点（早期介入、個別化された支援など）を放棄することになり、問題解決ではなく逃避です。</li><li><strong>D) 予測結果を隠す:</strong> 透明性を損ない、問題を隠蔽するだけで、根本的な解決にはなりません。</li></ul><p>教育の公平性を確保しながら、AIを活用して全ての学生の学習成果を向上させることが目標です。</p>",
  "resources": []
}
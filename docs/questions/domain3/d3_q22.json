{
  "id": "d3_q22",
  "type": "single",
  "text": "次のシナリオを考えてください： 「教育機関が学生の成績予測AIを導入したが、社会経済的背景による偏りが懸念される」 適切な対応策はどれですか？",
  "choices": [
    {
      "label": "A",
      "text": "社会経済的データを完全に除外する"
    },
    {
      "label": "B",
      "text": "公平性制約を加えたモデルの再設計と継続的なモニタリング"
    },
    {
      "label": "C",
      "text": "AIの使用を中止する"
    },
    {
      "label": "D",
      "text": "予測結果を隠す"
    }
  ],
  "correct": [
    1
  ],
  "explanation": "正解はB「公平性制約を加えたモデルの再設計と継続的なモニタリング」です。\n\n教育機関における成績予測AIで社会経済的背景による偏りが懸念される場合、問題を認識し、積極的に対処することが重要です。単に問題を無視したり、システムを放棄したりするのではなく、公平性を確保しながらAIの利点を活かす方法を追求すべきです。\n\n適切な対応策の内容：\n- 公平性制約の実装：異なる社会経済的グループ間で予測精度が均等になるようモデルを調整\n- バイアス検出：定期的にモデルの予測結果を分析し、偏りを特定\n- 継続的モニタリング：デプロイ後も公平性指標を監視し、問題を早期発見\n- 多様なステークホルダーの関与：学生、教員、保護者の意見を反映\n- 補完的な支援策：AIの予測に基づいて、不利な立場の学生への追加支援を提供\n\n他の選択肢が不適切な理由：\n- A「社会経済的データを完全に除外する」：データを除外しても、他の変数を通じて間接的にバイアスが入る可能性があり、根本的な解決にはなりません。\n- C「AIの使用を中止する」：問題解決ではなく、技術の利点を放棄することになります。\n- D「予測結果を隠す」：透明性に反し、問題を隠蔽することになります。\n\n教育の公平性を確保しながら、AIを活用して全ての学生の学習成果を向上させることが目標です。",
  "resources": []
}
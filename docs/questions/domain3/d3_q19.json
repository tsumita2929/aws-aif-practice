{
  "id": "d3_q19",
  "type": "single",
  "text": "次のシナリオを考えてください： 「金融機関がAIを使用して融資審査を行っているが、決定理由を顧客に説明する必要がある」 この要求に対応するための最も適切なアプローチはどれですか？",
  "choices": [
    {
      "label": "A",
      "text": "AIの使用を隠す"
    },
    {
      "label": "B",
      "text": "LIME、SHAPなどの説明可能性ツールを実装する"
    },
    {
      "label": "C",
      "text": "決定理由は企業秘密として開示しない"
    },
    {
      "label": "D",
      "text": "より複雑なモデルを使用する"
    }
  ],
  "correct": [
    1
  ],
  "explanation": "正解はB「LIME、SHAPなどの説明可能性ツールを実装する」です。\n\n金融機関の融資審査において、AIの決定理由を説明することは、規制要件の遵守と顧客の信頼獲得の両面で極めて重要です。多くの国では、信用判断に関して説明を求める権利が法的に保護されています。\n\n説明可能性ツールの利点：\n- LIME（Local Interpretable Model-agnostic Explanations）：個別の予測に対して、どの特徴が最も影響したかを説明\n- SHAP（SHapley Additive exPlanations）：ゲーム理論に基づいて各特徴の貢献度を計算\n- 規制準拠：GDPR、米国のECOA（Equal Credit Opportunity Act）などの要件を満たす\n- 信頼構築：顧客が決定プロセスを理解することで、AIシステムへの信頼が向上\n- 改善機会の発見：説明を通じてモデルの問題点や改善点を特定\n\n他の選択肢が不適切な理由：\n- A「AIの使用を隠す」：透明性に反し、規制違反となる可能性があります。\n- C「決定理由は企業秘密として開示しない」：多くの法域で説明の権利が保護されており、開示拒否は違法となる場合があります。\n- D「より複雑なモデルを使用する」：複雑化は説明可能性を低下させ、問題を悪化させます。\n\n金融分野では、説明可能性と性能のバランスを取りながら、規制要件を満たすことが不可欠です。",
  "resources": []
}
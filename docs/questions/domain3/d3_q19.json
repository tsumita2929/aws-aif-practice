{
  "id": "d3_q19",
  "type": "single",
  "text": "次のシナリオを考えてください： 「金融機関がAIを使用して融資審査を行っているが、決定理由を顧客に説明する必要がある」 この要求に対応するための最も適切なアプローチはどれですか？",
  "choices": [
    {
      "label": "A",
      "text": "AIの使用を隠す"
    },
    {
      "label": "B",
      "text": "LIME、SHAPなどの説明可能性ツールを実装する"
    },
    {
      "label": "C",
      "text": "決定理由は企業秘密として開示しない"
    },
    {
      "label": "D",
      "text": "より複雑なモデルを使用する"
    }
  ],
  "correct": [
    1
  ],
  "explanation": "<h5>詳細解説</h5><p>正解はB「LIME、SHAPなどの説明可能性ツールを実装する」です。</p><p>金融機関の融資審査において、AIの決定理由を説明することは、規制要件の遵守と顧客の信頼獲得の両面で極めて重要です。多くの国では、信用判断に関して説明を求める権利が法的に保護されています。</p><h5>説明可能性ツールの利点</h5><ul><li>LIME（Local Interpretable Model-agnostic Explanations）：個別の予測に対して、どの特徴が最も影響したかを説明</li><li>SHAP（SHapley Additive exPlanations）：ゲーム理論に基づいて各特徴の貢献度を計算</li><li>規制準拠：GDPR、米国のECOA（Equal Credit Opportunity Act）などの要件を満たす</li><li>信頼構築：顧客が決定プロセスを理解することで、AIシステムへの信頼が向上</li><li>改善機会の発見：説明を通じてモデルの問題点や改善点を特定</li></ul><h5>なぜ他の選択肢が間違っているのか</h5><ul><li><strong>A) AIの使用を隠す:</strong> AIの使用を隠すことは透明性の原則に反し、多くの国で規制違反となります。顧客は意思決定に使用された方法を知る権利があります。</li><li><strong>C) 決定理由は企業秘密として開示しない:</strong> 金融分野では、融資拒否の理由を説明する法的義務があります（米国のECOA、EUのGDPRなど）。</li><li><strong>D) より複雑なモデルを使用する:</strong> 複雑なモデルは説明可能性を低下させ、問題を悪化させます。金融分野では解釈可能なモデルが望まれます。</li></ul><p>金融分野では、説明可能性と性能のバランスを取りながら、規制要件を満たすことが不可欠です。</p>",
  "resources": []
}
{
  "id": "d3_q37",
  "type": "single",
  "text": "次のシナリオを考えてください： 「AIによる信用スコアリングシステムが特定の地域の住民に不利な判定をしている」 この「レッドライニング」問題への対処法はどれですか？",
  "choices": [
    {
      "label": "A",
      "text": "地域情報をより重視する"
    },
    {
      "label": "B",
      "text": "地域情報を適切に処理し、他の要因とのバランスを取る"
    },
    {
      "label": "C",
      "text": "システムをそのまま使用する"
    },
    {
      "label": "D",
      "text": "信用スコアリングを廃止する"
    }
  ],
  "correct": [
    1
  ],
  "explanation": "<h5>詳細解説</h5><p>正解はB「地域情報を適切に処理し、他の要因とのバランスを取る」です。</p><p>レッドライニング（Redlining）は、特定の地域（多くの場合、マイノリティが多く住む地域）の住民に対して、不当にサービスを拒否したり不利な条件を課したりする差別的な慣行です。AIシステムがこのような差別を再現しないよう、慎重な対応が必要です。</p><h5>適切な対処法</h5><h5>1. 地域情報の適切な処理</h5><ul><li>地域を直接的な判断基準として使用しない</li><li>地域と相関する他の要因（収入、教育など）を慎重に評価</li><li>プロキシ変数による間接的差別の防止</li><li>地域の社会経済的背景の考慮</li></ul><h5>2. バランスの取れた評価</h5><ul><li>個人の信用力を多面的に評価</li><li>地域要因以外の指標を重視</li><li>公平性制約を組み込んだアルゴリズム</li><li>代替データソースの活用</li></ul><h5>3. 継続的な監視と改善</h5><ul><li>地域別の承認率の定期的な分析</li><li>差別的パターンの早期発見</li><li>影響を受けるコミュニティとの対話</li><li>モデルの定期的な再評価</li></ul><h5>なぜ他の選択肢が間違っているのか</h5><ul><li><strong>A) 地域情報をより重視する:</strong> 地域情報をさらに重視することは、レッドライニング問題を悪化させ、差別を強化します。</li><li><strong>C) システムをそのまま使用する:</strong> 差別的なシステムを修正せずに使用し続けることは、法的・倫理的に許されません。</li><li><strong>D) 信用スコアリングを廃止する:</strong> 信用スコアリング自体は有用なツールであり、問題はその実装方法です。完全廃止は非現実的です。</li></ul><p>公平な金融アクセスは基本的人権であり、技術はこれを促進すべきです。</p>",
  "resources": []
}
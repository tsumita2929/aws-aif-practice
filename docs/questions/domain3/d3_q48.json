{
  "id": "d3_q48",
  "type": "multiple",
  "text": "【複数選択】 生成AIの透明性を確保するための施策として適切なものを2つ選択してください。",
  "choices": [
    {
      "label": "A",
      "text": "AI生成コンテンツであることを明示する透かし技術の実装"
    },
    {
      "label": "B",
      "text": "使用したモデルとプロンプトの開示"
    },
    {
      "label": "C",
      "text": "生成プロセスを完全にブラックボックス化する"
    },
    {
      "label": "D",
      "text": "ユーザーに生成AIの使用を隠す"
    },
    {
      "label": "E",
      "text": "生成結果の信頼度スコアを提供する"
    }
  ],
  "correct": [
    0,
    4
  ],
  "explanation": "正解はA「AI生成コンテンツであることを明示する透かし技術の実装」とE「生成結果の信頼度スコアを提供する」です。\n\n生成AIの透明性は、ユーザーの信頼獲得と責任ある利用のために不可欠です。透明性を確保することで、ユーザーは情報の出所と信頼性を適切に判断できます。\n\n適切な透明性確保の施策：\n\nA「AI生成コンテンツであることを明示する透かし技術の実装」：\n- デジタル透かしや可視透かしによる識別\n- 改ざん検知機能の組み込み\n- 機械可読な識別子の埋め込み\n- ユーザーへの明確な表示\n\nE「生成結果の信頼度スコアを提供する」：\n- 生成内容の確実性を数値化\n- ユーザーの判断材料の提供\n- 不確実な部分の明示\n- リスクレベルの可視化\n\n他の選択肢が不適切な理由：\n- B「使用したモデルとプロンプトの開示」：技術的詳細の開示は必ずしも必要ではなく、セキュリティリスクやプライバシーの問題を引き起こす可能性があります。\n- C「生成プロセスを完全にブラックボックス化する」：透明性の正反対であり、信頼を損ないます。\n- D「ユーザーに生成AIの使用を隠す」：欺瞞的であり、倫理的・法的に問題があります。\n\n透明性の追加的な要素：\n- 生成AIの限界と制約の説明\n- データソースの概要（個人情報を除く）\n- 更新頻度と改善プロセス\n- フィードバック機構の提供\n\n透明性は、技術的な実装と適切なコミュニケーションの両方によって実現されます。",
  "resources": []
}
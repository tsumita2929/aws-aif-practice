{
  "id": "d3_q21",
  "type": "single",
  "text": "「アルゴリズムの説明責任」を果たすために必要な要素はどれですか？",
  "choices": [
    {
      "label": "A",
      "text": "ソースコードの完全な公開"
    },
    {
      "label": "B",
      "text": "意思決定プロセスの透明性と影響評価の実施"
    },
    {
      "label": "C",
      "text": "開発者の個人情報の公開"
    },
    {
      "label": "D",
      "text": "全ての計算過程の詳細な記録"
    }
  ],
  "correct": [
    1
  ],
  "explanation": "<h5>詳細解説</h5><p>正解はB「意思決定プロセスの透明性と影響評価の実施」です。</p><p>アルゴリズムの説明責任（Algorithmic Accountability）とは、AIシステムの意思決定が社会に与える影響に対して責任を持ち、その決定プロセスを説明できることを指します。</p><h5>説明責任を果たすための要素</h5><ul><li>意思決定プロセスの透明性：どのようにして結論に至ったかを理解可能な形で説明</li><li>影響評価の実施：システムが個人や社会に与える影響を事前・事後に評価</li><li>監査可能性：第三者がシステムの動作を検証できる仕組み</li><li>是正措置：問題が発見された場合の対応プロセス</li><li>ステークホルダーとのコミュニケーション</li></ul><h5>なぜ他の選択肢が間違っているのか</h5><ul><li><strong>A) ソースコードの完全な公開:</strong> ソースコードの公開は必須ではなく、知的財産権やセキュリティ上の問題もあります。重要なのは動作の説明であり、実装の詳細ではありません。</li><li><strong>C) 開発者の個人情報の公開:</strong> 開発者の個人情報は説明責任とは無関係で、プライバシー侵害のリスクがあります。組織としての責任が重要です。</li><li><strong>D) 全ての計算過程の詳細な記録:</strong> 全ての計算過程の記録は非現実的で、情報過多によりかえって理解を妨げます。適切な抽象化が必要です。</li></ul><p>説明責任は、適切な抽象度での説明、文書化、監査証跡、継続的な改善のバランスを取ることで実現されます。</p>",
  "resources": []
}
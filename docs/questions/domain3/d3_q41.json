{
  "id": "d3_q41",
  "type": "single",
  "text": "「AIによる差別」を防ぐための技術的アプローチとして適切でないものはどれですか？",
  "choices": [
    {
      "label": "A",
      "text": "公平性制約の実装"
    },
    {
      "label": "B",
      "text": "敵対的デバイアシング"
    },
    {
      "label": "C",
      "text": "センシティブ属性の完全な無視（カラーブラインド）"
    },
    {
      "label": "D",
      "text": "継続的なモニタリングと調整"
    }
  ],
  "correct": [
    2
  ],
  "explanation": "<h5>詳細解説</h5><p>正解はC「センシティブ属性の完全な無視（カラーブラインド）」です。</p><p>センシティブ属性（人種、性別、年齢など）を完全に無視する「カラーブラインド」アプローチは、一見公平に見えますが、実際には既存の不平等を無視し、間接的な差別を見逃す可能性があるため、適切ではありません。</p><h5>カラーブラインドアプローチの問題点</h5><ul><li>プロキシ変数による間接差別：他の変数（郵便番号、学歴など）を通じて間接的に差別が発生</li><li>既存の不平等の無視：歴史的・構造的な不平等を考慮しない</li><li>公平性の検証不能：センシティブ属性を測定しないと、差別の有無を確認できない</li><li>積極的是正措置の不可能：不利な立場のグループへの支援ができない</li></ul><h5>適切な技術的アプローチ</h5><ul><li>A「公平性制約の実装」：アルゴリズムに公平性の条件を組み込み、差別的な結果を防ぐ</li><li>B「敵対的デバイアシング」：敵対的学習を用いてバイアスを除去する高度な技術</li><li>D「継続的なモニタリングと調整」：デプロイ後も公平性を監視し、必要に応じて調整</li></ul><h5>その他の有効なアプローチ</h5><ul><li>公平性を考慮したデータサンプリング</li><li>多目的最適化（精度と公平性のバランス）</li><li>因果推論を用いた公平性の確保</li></ul><p>真の公平性を達成するには、センシティブ属性を認識し、適切に対処する必要があります。</p><h5>なぜ他の選択肢が間違っているのか</h5><ul><li><strong>A) 公平性制約の実装:</strong> これは差別を防ぐための有効な技術的アプローチで、アルゴリズムに公平性の条件を組み込みます。</li><li><strong>B) 敵対的デバイアシング:</strong> 敵対的学習を用いてバイアスを除去する高度な技術で、差別防止に有効です。</li><li><strong>D) 継続的なモニタリングと調整:</strong> デプロイ後も公平性を監視し、必要に応じて調整することは差別防止に不可欠です。</li></ul>",
  "resources": []
}
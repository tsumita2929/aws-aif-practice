{
  "id": "d3_q41",
  "type": "single",
  "text": "「AIによる差別」を防ぐための技術的アプローチとして適切でないものはどれですか？",
  "choices": [
    {
      "label": "A",
      "text": "公平性制約の実装"
    },
    {
      "label": "B",
      "text": "敵対的デバイアシング"
    },
    {
      "label": "C",
      "text": "センシティブ属性の完全な無視（カラーブラインド）"
    },
    {
      "label": "D",
      "text": "継続的なモニタリングと調整"
    }
  ],
  "correct": [
    2
  ],
  "explanation": "正解はC「センシティブ属性の完全な無視（カラーブラインド）」です。\n\nセンシティブ属性（人種、性別、年齢など）を完全に無視する「カラーブラインド」アプローチは、一見公平に見えますが、実際には既存の不平等を無視し、間接的な差別を見逃す可能性があるため、適切ではありません。\n\nカラーブラインドアプローチの問題点：\n- プロキシ変数による間接差別：他の変数（郵便番号、学歴など）を通じて間接的に差別が発生\n- 既存の不平等の無視：歴史的・構造的な不平等を考慮しない\n- 公平性の検証不能：センシティブ属性を測定しないと、差別の有無を確認できない\n- 積極的是正措置の不可能：不利な立場のグループへの支援ができない\n\n適切な技術的アプローチ：\n- A「公平性制約の実装」：アルゴリズムに公平性の条件を組み込み、差別的な結果を防ぐ\n- B「敵対的デバイアシング」：敵対的学習を用いてバイアスを除去する高度な技術\n- D「継続的なモニタリングと調整」：デプロイ後も公平性を監視し、必要に応じて調整\n\nその他の有効なアプローチ：\n- 公平性を考慮したデータサンプリング\n- 多目的最適化（精度と公平性のバランス）\n- 因果推論を用いた公平性の確保\n\n真の公平性を達成するには、センシティブ属性を認識し、適切に対処する必要があります。",
  "resources": []
}
{
  "id": "d3_q49",
  "type": "single",
  "text": "AIシステムの「説明責任（Accountability）」を確保するために必要な要素として最も重要なものはどれですか？",
  "choices": [
    {
      "label": "A",
      "text": "システムの処理速度の向上"
    },
    {
      "label": "B",
      "text": "意思決定プロセスの文書化と監査証跡の保持"
    },
    {
      "label": "C",
      "text": "より複雑なアルゴリズムの採用"
    },
    {
      "label": "D",
      "text": "完全な自動化の実現"
    }
  ],
  "correct": [
    1
  ],
  "explanation": "正解はB「意思決定プロセスの文書化と監査証跡の保持」です。\n\nAIシステムの説明責任（Accountability）は、システムの決定や動作に対して責任を持ち、必要に応じてその理由を説明できることを意味します。これは、規制遵守、信頼構築、継続的改善のために不可欠です。\n\n意思決定プロセスの文書化と監査証跡が重要な理由：\n\n1. 意思決定プロセスの文書化：\n- アルゴリズムの選択理由と設計決定\n- データソースとその選定基準\n- 性能指標と評価方法\n- リスク評価と軽減策\n- 倫理的考慮事項\n\n2. 監査証跡の保持：\n- システムの全ての決定の記録\n- 入力データと出力結果の保存\n- 設定変更とその理由\n- エラーと異常の記録\n- ユーザーのフィードバック\n\n3. 説明責任の実現：\n- 問題発生時の原因究明\n- 規制当局への報告\n- 利害関係者への説明\n- 継続的な改善の基盤\n- 法的紛争への対応\n\n他の選択肢が不適切な理由：\n- A「システムの処理速度の向上」：性能は重要ですが、説明責任とは直接関係ありません。\n- C「より複雑なアルゴリズムの採用」：複雑性の増加は説明責任を困難にする可能性があります。\n- D「完全な自動化の実現」：自動化と説明責任は別の概念であり、むしろ人間の関与が重要です。\n\n適切な文書化と記録保持は、AIシステムの透明性、信頼性、改善可能性の基盤となります。",
  "resources": []
}
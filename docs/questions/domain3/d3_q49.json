{
  "id": "d3_q49",
  "type": "single",
  "text": "AIシステムの「説明責任（Accountability）」を確保するために必要な要素として最も重要なものはどれですか？",
  "choices": [
    {
      "label": "A",
      "text": "システムの処理速度の向上"
    },
    {
      "label": "B",
      "text": "意思決定プロセスの文書化と監査証跡の保持"
    },
    {
      "label": "C",
      "text": "より複雑なアルゴリズムの採用"
    },
    {
      "label": "D",
      "text": "完全な自動化の実現"
    }
  ],
  "correct": [
    1
  ],
  "explanation": "<h5>詳細解説</h5><p>正解はB「意思決定プロセスの文書化と監査証跡の保持」です。</p><p>AIシステムの説明責任（Accountability）は、システムの決定や動作に対して責任を持ち、必要に応じてその理由を説明できることを意味します。これは、規制遵守、信頼構築、継続的改善のために不可欠です。</p><h5>意思決定プロセスの文書化と監査証跡が重要な理由</h5><h5>1. 意思決定プロセスの文書化</h5><ul><li>アルゴリズムの選択理由と設計決定</li><li>データソースとその選定基準</li><li>性能指標と評価方法</li><li>リスク評価と軽減策</li><li>倫理的考慮事項</li></ul><h5>2. 監査証跡の保持</h5><ul><li>システムの全ての決定の記録</li><li>入力データと出力結果の保存</li><li>設定変更とその理由</li><li>エラーと異常の記録</li><li>ユーザーのフィードバック</li></ul><h5>3. 説明責任の実現</h5><ul><li>問題発生時の原因究明</li><li>規制当局への報告</li><li>利害関係者への説明</li><li>継続的な改善の基盤</li><li>法的紛争への対応</li></ul><h5>なぜ他の選択肢が間違っているのか</h5><ul><li><strong>A) システムの処理速度の向上:</strong> 処理速度は技術的性能であり、説明責任とは無関係です。速くても説明できないシステムは信頼されません。</li><li><strong>C) より複雑なアルゴリズムの採用:</strong> 複雑なアルゴリズムは説明可能性を低下させ、説明責任を果たすことを困難にします。</li><li><strong>D) 完全な自動化の実現:</strong> 完全自動化は人間の監督や介入を排除し、説明責任の履行を困難にします。</li></ul><p>適切な文書化と記録保持は、AIシステムの透明性、信頼性、改善可能性の基盤となります。</p>",
  "resources": []
}
{
  "id": "d3_q9",
  "type": "single",
  "text": "AIシステムの「公平性（Fairness）」を評価する際、考慮すべき要素として適切でないものはどれですか？",
  "choices": [
    {
      "label": "A",
      "text": "異なる人口統計グループ間での性能差"
    },
    {
      "label": "B",
      "text": "保護属性（性別、人種など）に対する偏り"
    },
    {
      "label": "C",
      "text": "システムの実行速度"
    },
    {
      "label": "D",
      "text": "意思決定の透明性"
    }
  ],
  "correct": [
    2
  ],
  "explanation": "<h5>詳細解説</h5><p>正解はC「システムの実行速度」です。</p><p>AIシステムの公平性（Fairness）を評価する際、システムの実行速度は考慮すべき要素ではありません。実行速度は技術的な性能指標であり、公平性とは直接関係がありません。</p><h5>公平性評価で考慮すべき要素</h5><ul><li>A「異なる人口統計グループ間での性能差」：これは公平性の重要な指標です。全てのグループに対して同等の性能を発揮することが求められます。</li><li>B「保護属性（性別、人種など）に対する偏り」：保護属性に基づく差別がないかを確認することは公平性評価の中核です。</li><li>D「意思決定の透明性」：公平性を確保するためには、AIがどのように意思決定を行っているかを理解できることが重要です。</li></ul><p>公平性の評価には、統計的パリティ、機会の平等、個人の公平性など、様々な定義と測定方法があり、用途に応じて適切な指標を選択する必要があります。</p><h5>なぜ他の選択肢が間違っているのか</h5><ul><li><strong>A) 異なる人口統計グループ間での性能差:</strong> これは公平性評価の重要な要素です。全グループで同等の性能を確保することは公平性の基本です。</li><li><strong>B) 保護属性（性別、人種など）に対する偏り:</strong> 保護属性への偏りの検出と排除は、公平性評価の中核的な要素です。</li><li><strong>D) 意思決定の透明性:</strong> 透明性は公平性を検証し、バイアスを発見するために必要な要素です。</li></ul>",
  "resources": []
}
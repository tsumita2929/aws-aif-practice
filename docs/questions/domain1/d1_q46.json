{
  "id": "d1_q46",
  "type": "single",
  "text": "大規模言語モデル（LLM）のファインチューニングにおいて、「カタストロフィック・フォゲッティング」を防ぐための最も効果的な手法はどれですか？",
  "choices": [
    {
      "label": "A",
      "text": "学習率を極端に高く設定する"
    },
    {
      "label": "B",
      "text": "Elastic Weight Consolidation（EWC）やLoRA（Low-Rank Adaptation）を使用する"
    },
    {
      "label": "C",
      "text": "元のモデルのパラメータを完全に固定する"
    },
    {
      "label": "D",
      "text": "バッチサイズを最小にする"
    }
  ],
  "correct": [
    1
  ],
  "explanation": "\n                <h5>詳細解説</h5>\n                <p>カタストロフィック・フォゲッティング（破滅的忘却）は、新しいタスクの学習時に以前学習した知識が失われる現象です。EWCやLoRAなどの手法により、この問題を効果的に緩和できます。</p>\n                \n                <h5>カタストロフィック・フォゲッティングとは</h5>\n                <ul>\n                    <li><strong>現象の説明：</strong>\n                        <ul>\n                            <li>事前学習済みモデルの一般的な知識が失われる</li>\n                            <li>新タスクに過度に特化してしまう</li>\n                            <li>汎用性の低下と性能劣化</li>\n                        </ul>\n                    </li>\n                    <li><strong>発生メカニズム：</strong>\n                        <ul>\n                            <li>重要なパラメータが大きく更新される</li>\n                            <li>タスク間の干渉</li>\n                            <li>限られたモデル容量での競合</li>\n                        </ul>\n                    </li>\n                </ul>\n                \n                <h5>効果的な対策手法</h5>\n                <ul>\n                    <li><strong>LoRA（Low-Rank Adaptation）：</strong>\n                        <ul>\n                            <li>低ランク行列分解による効率的な適応</li>\n                            <li>元のモデルパラメータは固定、追加パラメータのみ学習</li>\n                            <li>メモリ効率的で高速</li>\n                            <li>複数のLoRAアダプターを切り替え可能</li>\n                        </ul>\n                    </li>\n                    <li><strong>EWC（Elastic Weight Consolidation）：</strong>\n                        <ul>\n                            <li>重要なパラメータを特定し、変更を制限</li>\n                            <li>フィッシャー情報行列を使用</li>\n                            <li>以前のタスクへの影響を最小化</li>\n                        </ul>\n                    </li>\n                    <li><strong>その他の手法：</strong>\n                        <ul>\n                            <li>Progressive Neural Networks：新しいモジュールを追加</li>\n                            <li>PackNet：パラメータの部分集合を各タスクに割り当て</li>\n                            <li>Memory Replay：過去のデータを保持して再学習</li>\n                        </ul>\n                    </li>\n                </ul>\n                \n                <h5>なぜ他の選択肢が不適切なのか</h5>\n                <ul>\n                    <li><strong>A（高学習率）：</strong> 逆効果。高学習率は破滅的忘却を加速させる</li>\n                    <li><strong>C（完全固定）：</strong> 新しいタスクの学習が不可能になる</li>\n                    <li><strong>D（最小バッチサイズ）：</strong> 勾配のノイズが増加し、学習が不安定になる</li>\n                </ul>\n                \n                <h5>LoRAの実装例</h5>\n                <pre><code># LoRAの基本的な考え方\nclass LoRALayer(nn.Module):\n    def __init__(self, original_layer, rank=16):\n        super().__init__()\n        self.original_layer = original_layer\n        \n        # 低ランク行列 A と B\n        self.lora_A = nn.Parameter(\n            torch.randn(original_layer.in_features, rank)\n        )\n        self.lora_B = nn.Parameter(\n            torch.zeros(rank, original_layer.out_features)\n        )\n        self.scaling = 0.01\n        \n        # 元の層は固定\n        for param in original_layer.parameters():\n            param.requires_grad = False\n    \n    def forward(self, x):\n        # 元の層の出力 + LoRA適応\n        return self.original_layer(x) +                (x @ self.lora_A @ self.lora_B) * self.scaling</code></pre>\n                \n                <h5>実務での選択基準</h5>\n                <table border=\"1\" style=\"width: 100%; margin: 10px 0;\">\n                    <tr>\n                        <th>手法</th>\n                        <th>適用場面</th>\n                        <th>メリット</th>\n                        <th>デメリット</th>\n                    </tr>\n                    <tr>\n                        <td>LoRA</td>\n                        <td>LLMの特定ドメイン適応</td>\n                        <td>効率的、切り替え可能</td>\n                        <td>表現力に制限</td>\n                    </tr>\n                    <tr>\n                        <td>EWC</td>\n                        <td>連続学習タスク</td>\n                        <td>理論的基盤</td>\n                        <td>計算コスト高</td>\n                    </tr>\n                    <tr>\n                        <td>Prefix Tuning</td>\n                        <td>プロンプトベースタスク</td>\n                        <td>パラメータ数少</td>\n                        <td>タスク依存</td>\n                    </tr>\n                </table>\n                \n                <h5>AWSでの実装</h5>\n                <p>・Amazon SageMaker：LoRAを使用したLLMファインチューニング<br>\n                ・Amazon Bedrock：カスタマイズ機能でドメイン適応<br>\n                ・パラメータ効率的な学習でコスト削減</p>\n            <h5>なぜ他の選択肢が間違っているのか</h5><ul><li><strong>A) 学習率を極端に高く設定する:</strong> 高い学習率は破滅的忘却を加速させます。大きなパラメータ更新により、事前学習で獲得した知識が急速に失われてしまいます。</li><li><strong>C) 元のモデルのパラメータを完全に固定する:</strong> パラメータを完全に固定すると、新しいタスクへの適応ができなくなります。ファインチューニングの目的自体が達成できません。</li><li><strong>D) バッチサイズを最小にする:</strong> 小さなバッチサイズは勾配のノイズを増加させ、学習が不安定になります。カタストロフィック・フォゲッティングの防止には直接的な効果がありません。</li></ul>",
  "resources": []
}
{
  "id": "d1_q40",
  "type": "single",
  "text": "次のうち、時系列予測に特化したニューラルネットワークアーキテクチャはどれですか？",
  "choices": [
    {
      "label": "A",
      "text": "CNN（畳み込みニューラルネットワーク）"
    },
    {
      "label": "B",
      "text": "LSTM（Long Short-Term Memory）"
    },
    {
      "label": "C",
      "text": "オートエンコーダー"
    },
    {
      "label": "D",
      "text": "GAN（敵対的生成ネットワーク）"
    }
  ],
  "correct": [
    1
  ],
  "explanation": "\n                <h5>詳細解説</h5>\n                <p>LSTM（Long Short-Term Memory）は、時系列データの長期的な依存関係を学習できるRNN（Recurrent Neural Network）の改良版で、時系列予測に特化したアーキテクチャです。</p>\n                \n                <h5>LSTMの特徴と利点</h5>\n                <ul>\n                    <li><strong>長期記憶の保持：</strong>\n                        <ul>\n                            <li>ゲート機構により重要な情報を長期間保持</li>\n                            <li>従来のRNNの勾配消失問題を解決</li>\n                            <li>数百ステップ前の情報も活用可能</li>\n                        </ul>\n                    </li>\n                    <li><strong>3つのゲート機構：</strong>\n                        <ul>\n                            <li><strong>忘却ゲート：</strong> 不要な過去情報を忘れる</li>\n                            <li><strong>入力ゲート：</strong> 新しい情報の取り込みを制御</li>\n                            <li><strong>出力ゲート：</strong> 次の層への出力を制御</li>\n                        </ul>\n                    </li>\n                </ul>\n                \n                <h5>時系列予測での応用例</h5>\n                <ul>\n                    <li><strong>金融市場：</strong> 株価、為替レートの予測</li>\n                    <li><strong>需要予測：</strong> 売上、在庫管理</li>\n                    <li><strong>IoTセンサー：</strong> 異常検知、故障予測</li>\n                    <li><strong>気象予報：</strong> 天気パターンの予測</li>\n                    <li><strong>トラフィック予測：</strong> ウェブサイト、道路交通量</li>\n                </ul>\n                \n                <h5>実装例（Keras）</h5>\n                <pre><code>from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense\nimport numpy as np\n\n# 時系列データの準備（例：過去30日から翌日を予測）\ndef create_sequences(data, n_steps=30):\n    X, y = [], []\n    for i in range(len(data) - n_steps):\n        X.append(data[i:i+n_steps])\n        y.append(data[i+n_steps])\n    return np.array(X), np.array(y)\n\n# LSTMモデルの構築\nmodel = Sequential([\n    LSTM(50, activation='relu', input_shape=(30, 1)),\n    Dense(1)\n])\n\nmodel.compile(optimizer='adam', loss='mse')\nmodel.fit(X_train, y_train, epochs=100, batch_size=32)</code></pre>\n                \n                <h5>なぜ他のアーキテクチャが時系列に不適か</h5>\n                <ul>\n                    <li><strong>A（CNN）：</strong>\n                        <ul>\n                            <li>主に空間的パターンの認識に特化</li>\n                            <li>時系列では1D CNNとして使用可能だが、長期依存は苦手</li>\n                        </ul>\n                    </li>\n                    <li><strong>C（オートエンコーダー）：</strong>\n                        <ul>\n                            <li>次元削減や異常検知には有効</li>\n                            <li>時系列予測に特化していない</li>\n                        </ul>\n                    </li>\n                    <li><strong>D（GAN）：</strong>\n                        <ul>\n                            <li>データ生成に特化</li>\n                            <li>時系列生成には使えるが、予測タスクには不適</li>\n                        </ul>\n                    </li>\n                </ul>\n                \n                <h5>最新の時系列予測手法</h5>\n                <ul>\n                    <li><strong>Transformer：</strong> Attention機構で長期依存をより効率的に学習</li>\n                    <li><strong>GRU：</strong> LSTMの簡易版、計算効率が良い</li>\n                    <li><strong>Temporal Fusion Transformer：</strong> 解釈可能性も考慮</li>\n                </ul>\n                \n                <h5>AWSでの実装</h5>\n                <ul>\n                    <li><strong>Amazon Forecast：</strong> DeepAR（LSTMベース）を含む自動時系列予測</li>\n                    <li><strong>Amazon SageMaker：</strong> カスタムLSTMモデルの構築とデプロイ</li>\n                </ul>\n            ",
  "resources": []
}
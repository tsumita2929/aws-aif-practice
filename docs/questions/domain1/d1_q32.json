{
  "id": "d1_q32",
  "type": "single",
  "text": "次のシナリオを考えてください： 「製造業で品質検査の自動化を検討している。不良品の発生率は0.1%と非常に低い」 この異常検知タスクに適したアプローチはどれですか？",
  "choices": [
    {
      "label": "A",
      "text": "二値分類モデルを通常通り訓練する"
    },
    {
      "label": "B",
      "text": "One-Class SVMやオートエンコーダーなどの異常検知手法を使用する"
    },
    {
      "label": "C",
      "text": "不良品データを捨てて良品のみで学習する"
    },
    {
      "label": "D",
      "text": "ディープラーニングは使用できない"
    }
  ],
  "correct": [
    1
  ],
  "explanation": "\n                <h5>詳細解説</h5>\n                <p>不良品の発生率が0.1%という極端に不均衡なデータでは、通常の分類手法は機能しません。異常検知（Anomaly Detection）アプローチが必要です。</p>\n                \n                <h5>なぜ異常検知手法が適切か</h5>\n                <ul>\n                    <li><strong>データの不均衡：</strong> 99.9%が正常品、0.1%が不良品</li>\n                    <li><strong>学習の困難さ：</strong> 不良品サンプルが極端に少ない</li>\n                    <li><strong>未知の異常：</strong> 新しいタイプの不良品も検出したい</li>\n                </ul>\n                \n                <h5>推奨される異常検知手法</h5>\n                <ul>\n                    <li><strong>One-Class SVM：</strong>\n                        <ul>\n                            <li>正常データの境界を学習</li>\n                            <li>境界外のデータを異常と判定</li>\n                            <li>カーネルトリックで非線形境界も扱える</li>\n                        </ul>\n                    </li>\n                    <li><strong>オートエンコーダー：</strong>\n                        <ul>\n                            <li>正常データの特徴を圧縮・復元</li>\n                            <li>復元誤差が大きいものを異常と判定</li>\n                            <li>画像データに特に有効</li>\n                        </ul>\n                    </li>\n                    <li><strong>Isolation Forest：</strong>\n                        <ul>\n                            <li>異常値は少ない分割で孤立する原理を利用</li>\n                            <li>高速で大規模データにも適用可能</li>\n                        </ul>\n                    </li>\n                </ul>\n                \n                <h5>実装例（Python）</h5>\n                <pre><code>from sklearn.svm import OneClassSVM\nfrom sklearn.preprocessing import StandardScaler\n\n# 正常データのみで学習\nscaler = StandardScaler()\nX_normal_scaled = scaler.fit_transform(X_normal)\n\n# One-Class SVMの訓練\nmodel = OneClassSVM(nu=0.001)  # nu≈異常率\nmodel.fit(X_normal_scaled)\n\n# 予測（1:正常、-1:異常）\npredictions = model.predict(X_test_scaled)</code></pre>\n                \n                <h5>なぜ他の選択肢が誤りか</h5>\n                <ul>\n                    <li><strong>A：</strong> 不均衡データでは、全て正常と予測して99.9%の精度になってしまう</li>\n                    <li><strong>C：</strong> 不良品データは貴重な情報源、捨てるべきではない</li>\n                    <li><strong>D：</strong> ディープラーニングも異常検知に使用可能（VAEなど）</li>\n                </ul>\n                \n                <h5>AWSでの実装</h5>\n                <ul>\n                    <li><strong>Amazon Lookout for Equipment：</strong> 産業機器の異常検知</li>\n                    <li><strong>Amazon Lookout for Vision：</strong> 画像による品質検査</li>\n                    <li><strong>Amazon SageMaker：</strong> カスタム異常検知モデルの構築</li>\n                </ul>\n            <h5>なぜ他の選択肢が間違っているのか</h5><ul><li><strong>A) 二値分類モデルを通常通り訓練する:</strong> 極端に不均衡なデータ（99.9%対0.1%）では、モデルは常に「良品」と予測するだけで99.9%の精度を達成してしまい、不良品を全く検出できません。</li><li><strong>C) 不良品データを捨てて良品のみで学習する:</strong> 不良品データは貴重な情報源です。異常検知では正常データで学習しますが、不良品データは検証やしきい値調整に活用すべきです。</li><li><strong>D) ディープラーニングは使用できない:</strong> ディープラーニングも異常検知に有効です。Variational Autoencoder（VAE）やGANベースの異常検知など、多くの手法が存在します。</li></ul>",
  "resources": []
}
{
  "domain": 1,
  "group": 2,
  "title": "応用とモデル評価",
  "description": "推薦システム、評価指標、CNN、特徴量エンジニアリング、転移学習、次元の呪い、不均衡データ対策、最適化手法、汎化性能、教師なし学習",
  "questionCount": 10,
  "questions": [
    {
      "id": "d1_q8",
      "type": "single",
      "text": "ECサイトが購買履歴から次回購入商品を予測する場合、最適な機械学習アプローチはどれですか？",
      "choices": [
        {
          "label": "A",
          "text": "教師なしクラスタリングで顧客をグループ化"
        },
        {
          "label": "B",
          "text": "教師あり分類で商品カテゴリを予測"
        },
        {
          "label": "C",
          "text": "強化学習で試行錯誤的に学習"
        },
        {
          "label": "D",
          "text": "回帰分析で購入金額を予測"
        }
      ],
      "correct": [1],
      "explanation": "<h5>詳細解説</h5><p>購買履歴から商品予測は典型的な教師あり分類問題です。過去の購買データ（特徴量）と実際の購入商品（ラベル）のペアから学習します。</p><h5>なぜ他の選択肢が誤りなのか</h5><ul><li><strong>A:</strong> クラスタリングは顧客セグメンテーションには有効だが、具体的な商品予測はできない</li><li><strong>C:</strong> 強化学習は報酬ベースの学習で、明確な正解ラベルがある場合は非効率</li><li><strong>D:</strong> 回帰は連続値（金額）予測で、離散的な商品カテゴリ予測には不適</li></ul><h5>実装のポイント</h5><p>協調フィルタリング、コンテンツベース推薦、ハイブリッド手法を組み合わせ、Amazon Personalizeなどで実装可能。</p>",
      "resources": [{"title": "Amazon Personalize Developer Guide", "url": "https://docs.aws.amazon.com/personalize/latest/dg/what-is-personalize.html"}]
    },
    {
      "id": "d1_q9",
      "type": "single",
      "text": "クレジットカード不正検知で、不正取引が全体の0.1%の場合、モデル評価で最も重視すべき指標はどれですか？",
      "choices": [
        {
          "label": "A",
          "text": "精度（Accuracy）のみ"
        },
        {
          "label": "B",
          "text": "適合率（Precision）と再現率（Recall）のバランス"
        },
        {
          "label": "C",
          "text": "処理速度"
        },
        {
          "label": "D",
          "text": "モデルサイズ"
        }
      ],
      "correct": [1],
      "explanation": "<h5>詳細解説</h5><p>極端に不均衡なデータ（0.1% vs 99.9%）では、精度だけでは評価不十分です。全て正常と予測しても精度99.9%になりますが、不正を1件も検出できません。</p><h5>重要な評価指標</h5><ul><li><strong>再現率（Recall）:</strong> 実際の不正取引をどれだけ検出できたか（見逃し防止）</li><li><strong>適合率（Precision）:</strong> 不正と予測した中で実際に不正だった割合（誤検知削減）</li><li><strong>F1スコア:</strong> 両者のバランス</li><li><strong>AUC-ROC:</strong> 閾値に依存しない総合評価</li></ul><h5>ビジネスインパクト</h5><p>不正見逃し（偽陰性）→顧客損失、誤検知（偽陽性）→顧客体験悪化。コストを考慮した最適なバランスが重要。</p>",
      "resources": []
    },
    {
      "id": "d1_q10",
      "type": "single",
      "text": "畳み込みニューラルネットワーク（CNN）が画像認識で優れている根本的な理由は何ですか？",
      "choices": [
        {
          "label": "A",
          "text": "計算速度が速く効率的だから"
        },
        {
          "label": "B",
          "text": "局所的な空間パターンを階層的に学習できるから"
        },
        {
          "label": "C",
          "text": "テキストデータも同時に処理できるから"
        },
        {
          "label": "D",
          "text": "教師なし学習に特化しているから"
        }
      ],
      "correct": [1],
      "explanation": "<h5>詳細解説</h5><p>CNNは画像の階層的構造を効率的に学習します。浅い層でエッジや角を検出し、深い層で複雑な物体を認識します。</p><h5>CNNの主要な特徴</h5><ul><li><strong>畳み込み層:</strong> 局所的なパターン（フィルタ）を画像全体で共有</li><li><strong>プーリング層:</strong> 位置の微小変化に対する不変性を獲得</li><li><strong>階層的学習:</strong> 低次特徴→中次特徴→高次特徴へと段階的に抽象化</li></ul><h5>なぜ他の選択肢が誤りなのか</h5><ul><li><strong>A:</strong> CNNは実際には計算量が多く、GPUが必要</li><li><strong>C:</strong> CNNは画像専用設計、テキストにはRNN/Transformerが適切</li><li><strong>D:</strong> CNNは主に教師あり学習で使用される</li></ul>",
      "resources": []
    },
    {
      "id": "d1_q11",
      "type": "single",
      "text": "売上予測モデルの精度向上のため、日付データから新しい特徴量を作成したい。最も効果的な特徴エンジニアリング手法はどれですか？",
      "choices": [
        {
          "label": "A",
          "text": "日付を削除してモデルを簡潔にする"
        },
        {
          "label": "B",
          "text": "曜日、月、祝日フラグなどの周期的特徴を抽出"
        },
        {
          "label": "C",
          "text": "日付をそのまま数値として使用"
        },
        {
          "label": "D",
          "text": "ランダムな値に置き換える"
        }
      ],
      "correct": [1],
      "explanation": "<h5>詳細解説</h5><p>時系列データの特徴エンジニアリングでは、ビジネスロジックに基づく周期性の抽出が重要です。</p><h5>効果的な特徴抽出例</h5><ul><li><strong>時間的特徴:</strong> 曜日（週末効果）、月（季節性）、四半期</li><li><strong>イベント特徴:</strong> 祝日、セール期間、給料日</li><li><strong>ラグ特徴:</strong> 前日/前週/前年同期の売上</li><li><strong>移動統計量:</strong> 7日移動平均、トレンド</li></ul><h5>なぜ他の選択肢が誤りなのか</h5><ul><li><strong>A:</strong> 重要な時系列情報を失う</li><li><strong>C:</strong> 2024/01/01を20240101として扱うと、順序は保たれるが周期性を捉えられない</li><li><strong>D:</strong> 情報を完全に破壊してしまう</li></ul>",
      "resources": []
    },
    {
      "id": "d1_q12",
      "type": "single",
      "text": "医療画像診断AIを開発する際、一般画像で事前学習済みのモデルを活用する転移学習の最大の利点は何ですか？",
      "choices": [
        {
          "label": "A",
          "text": "医療知識が不要になる"
        },
        {
          "label": "B",
          "text": "少ない医療画像データでも高精度を達成できる"
        },
        {
          "label": "C",
          "text": "計算リソースが増加する"
        },
        {
          "label": "D",
          "text": "規制承認が不要になる"
        }
      ],
      "correct": [1],
      "explanation": "<h5>詳細解説</h5><p>転移学習により、ImageNetなどで学習した一般的な画像特徴（エッジ、形状、テクスチャ）を医療画像に活用できます。</p><h5>転移学習のメカニズム</h5><ul><li><strong>特徴抽出層:</strong> 低次の一般的特徴は再利用</li><li><strong>ファインチューニング:</strong> 医療画像特有の高次特徴を追加学習</li><li><strong>データ効率:</strong> 数百枚の医療画像でも実用的な精度</li></ul><h5>実装アプローチ</h5><p>1. 事前学習済みモデル（ResNet等）の最終層を除去<br>2. 医療画像用の新しい分類層を追加<br>3. 少ない学習率で全体を再訓練</p><h5>注意点</h5><p>医療知識は依然必要で、規制要件も満たす必要があります。</p>",
      "resources": []
    },
    {
      "id": "d1_q16",
      "type": "single",
      "text": "次元の呪い（Curse of Dimensionality）が引き起こす最も深刻な問題は何ですか？",
      "choices": [
        {
          "label": "A",
          "text": "モデルの学習時間が線形的に減少する"
        },
        {
          "label": "B",
          "text": "高次元空間でデータ点間の距離が意味を失う"
        },
        {
          "label": "C",
          "text": "特徴量が自動的に削減される"
        },
        {
          "label": "D",
          "text": "データの可視化が容易になる"
        }
      ],
      "correct": [1],
      "explanation": "<h5>詳細解説</h5><p>高次元空間では、全てのデータ点が互いに「遠く」なり、距離ベースの手法が機能しなくなります。</p><h5>次元の呪いの影響</h5><ul><li><strong>距離の無意味化:</strong> 1000次元では、ランダムな点間の距離がほぼ一定</li><li><strong>データの希薄化:</strong> 空間を埋めるのに必要なデータ量が指数関数的に増加</li><li><strong>過学習リスク:</strong> パラメータ数 > サンプル数になりやすい</li></ul><h5>対策手法</h5><ul><li><strong>次元削減:</strong> PCA、t-SNE、UMAP</li><li><strong>特徴選択:</strong> 重要な特徴量のみを使用</li><li><strong>正則化:</strong> L1/L2正則化で複雑性を制限</li><li><strong>深層学習:</strong> 自動的な特徴表現学習</li></ul>",
      "resources": []
    },
    {
      "id": "d1_q14",
      "type": "multiple",
      "text": "信用審査で承認90%、拒否10%の不均衡データに対する適切な対処法を2つ選択してください。",
      "choices": [
        {
          "label": "A",
          "text": "少数クラス（拒否）のデータを削除する"
        },
        {
          "label": "B",
          "text": "SMOTE（Synthetic Minority Over-sampling）を適用する"
        },
        {
          "label": "C",
          "text": "クラス重み付けでペナルティを調整する"
        },
        {
          "label": "D",
          "text": "精度（Accuracy）だけで評価する"
        }
      ],
      "correct": [1, 2],
      "explanation": "<h5>詳細解説</h5><p>不均衡データでは、少数クラスの情報を保持しながらバランスを改善する必要があります。</p><h5>推奨される手法</h5><ul><li><strong>B) SMOTE:</strong> 少数クラスの合成サンプルを生成し、決定境界を改善</li><li><strong>C) クラス重み付け:</strong> 損失関数で少数クラスの誤分類により大きなペナルティ</li></ul><h5>なぜ他の選択肢が誤りなのか</h5><ul><li><strong>A:</strong> 貴重な拒否データを削除すると、拒否パターンを学習できない</li><li><strong>D:</strong> 全て承認と予測しても精度90%となり、ビジネス的に無意味</li></ul><h5>実装例</h5><p>・アンダーサンプリング + オーバーサンプリングの組み合わせ<br>・コスト考慮学習：承認誤り < 拒否誤りのコスト設定<br>・アンサンブル：BalancedRandomForest等</p>",
      "resources": []
    },
    {
      "id": "d1_q15",
      "type": "single",
      "text": "ニューラルネットワークの学習で、損失関数が振動して収束しない。最も可能性の高い原因は何ですか？",
      "choices": [
        {
          "label": "A",
          "text": "学習率が小さすぎる"
        },
        {
          "label": "B",
          "text": "学習率が大きすぎる"
        },
        {
          "label": "C",
          "text": "データが多すぎる"
        },
        {
          "label": "D",
          "text": "正則化が強すぎる"
        }
      ],
      "correct": [1],
      "explanation": "<h5>詳細解説</h5><p>学習率が大きすぎると、最適解の周りを大きく振動し、収束できません。</p><h5>学習率と収束の関係</h5><ul><li><strong>大きすぎる学習率:</strong> 最適解を飛び越えて振動・発散</li><li><strong>適切な学習率:</strong> 滑らかに最適解に収束</li><li><strong>小さすぎる学習率:</strong> 収束は安定だが非常に遅い</li></ul><h5>診断と対策</h5><ul><li><strong>診断:</strong> 損失の推移をプロット、振動パターンを確認</li><li><strong>対策:</strong> 学習率を1/10に減少、学習率スケジューリング導入</li><li><strong>高度な手法:</strong> Adam、RMSpropなどの適応的学習率</li></ul><h5>実装例</h5><pre>learning_rate = 0.01  # 大きすぎる場合\nlearning_rate = 0.001  # 適切な開始値\n# 学習率減衰\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)</pre>",
      "resources": []
    },
    {
      "id": "d1_q25",
      "type": "single",
      "text": "モデルの汎化性能を評価する際、最も重要な原則は何ですか？",
      "choices": [
        {
          "label": "A",
          "text": "訓練データの精度を100%にする"
        },
        {
          "label": "B",
          "text": "最も複雑なモデルを選択する"
        },
        {
          "label": "C",
          "text": "訓練データとは独立したテストデータで評価する"
        },
        {
          "label": "D",
          "text": "テストデータも訓練に使用する"
        }
      ],
      "correct": [2],
      "explanation": "<h5>詳細解説</h5><p>汎化性能は、未知のデータに対する予測能力です。訓練に使用していない独立したテストデータでの評価が必須です。</p><h5>適切な評価プロセス</h5><ul><li><strong>データ分割:</strong> 訓練用(60%)、検証用(20%)、テスト用(20%)</li><li><strong>検証用:</strong> ハイパーパラメータ調整</li><li><strong>テスト用:</strong> 最終的な性能評価（1回のみ使用）</li></ul><h5>なぜ他の選択肢が誤りなのか</h5><ul><li><strong>A:</strong> 訓練データ100%は過学習の典型例</li><li><strong>B:</strong> 複雑なモデルは過学習しやすい</li><li><strong>D:</strong> データリーケージとなり、評価が無意味になる</li></ul><h5>ベストプラクティス</h5><p>時系列データは時間順分割、クロスバリデーションで頑健性確認、本番環境に近い条件でテスト。</p>",
      "resources": []
    },
    {
      "id": "d1_q26",
      "type": "single",
      "text": "次のうち、教師なし学習のタスクでないものはどれですか？",
      "choices": [
        {
          "label": "A",
          "text": "顧客の購買パターンによるセグメンテーション"
        },
        {
          "label": "B",
          "text": "製造ラインでの異常検知"
        },
        {
          "label": "C",
          "text": "手書き数字の分類"
        },
        {
          "label": "D",
          "text": "高次元データの可視化"
        }
      ],
      "correct": [2],
      "explanation": "<h5>詳細解説</h5><p>手書き数字の分類は、正解ラベル（0-9）が必要な教師あり学習の典型例です。</p><h5>教師なし学習の特徴</h5><ul><li><strong>ラベルなし:</strong> 正解データを使わずにパターンを発見</li><li><strong>探索的:</strong> データの隠れた構造を明らかにする</li><li><strong>前処理:</strong> 教師あり学習の前段階としても活用</li></ul><h5>各選択肢の詳細</h5><ul><li><strong>A) セグメンテーション:</strong> K-meansなどでラベルなしに顧客グループ発見</li><li><strong>B) 異常検知:</strong> 正常データのみから異常パターンを検出</li><li><strong>C) 手書き数字分類:</strong> MNISTなど、0-9のラベル付きデータで学習</li><li><strong>D) 可視化:</strong> PCA、t-SNEで高次元を2D/3Dに圧縮</li></ul>",
      "resources": []
    }
  ]
}
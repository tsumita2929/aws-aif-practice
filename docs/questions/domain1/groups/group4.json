{
  "domain": 1,
  "group": 4,
  "title": "プロジェクト実践",
  "description": "MLライフサイクル、異常検知、バイアス分散トレードオフ、埋め込み、デバッグ技術、勾配消失問題、データリーケージ、交差検証、LSTM、推薦システム",
  "questionCount": 10,
  "questions": [
    {
      "id": "d1_q31",
      "type": "single",
      "text": "機械学習プロジェクトの成功率を高めるため、開始時に最優先で実施すべきステップはどれですか？",
      "choices": [
        {
          "label": "A",
          "text": "最新のアルゴリズムの選択"
        },
        {
          "label": "B",
          "text": "ビジネス課題の理解と明確な問題定義"
        },
        {
          "label": "C",
          "text": "大量データの収集開始"
        },
        {
          "label": "D",
          "text": "本番環境の構築"
        }
      ],
      "correct": [1],
      "explanation": "<h5>詳細解説</h5><p>MLプロジェクトの失敗の約40%は問題定義の不備が原因です。技術的な実装よりも前に、解決すべきビジネス課題の明確化と測定可能な成功基準の設定が最重要です。</p><h5>効果的な問題定義のポイント</h5><ul><li><strong>課題の具体化:</strong> 「AIで売上向上」→「離脱予測で解約率15%→10%削減」</li><li><strong>成功指標の定義:</strong> KPI、ROI、実装可能性の事前評価</li><li><strong>制約条件の整理:</strong> 予算、期間、技術的制約、規制要件</li></ul><h5>問題定義フレームワーク</h5><ol><li>現状の課題分析と定量化</li><li>MLで解決可能性の検証</li><li>ビジネス価値の試算</li><li>最小実現可能製品（MVP）の設計</li></ol><h5>なぜ他が後回しか</h5><ul><li>A,C,D: 問題が不明確だと適切な選択ができない</li><li>統計: 明確な問題定義があるプロジェクトの成功率は70%以上</li></ul>",
      "resources": []
    },
    {
      "id": "d1_q32",
      "type": "single",
      "text": "製造業で不良品率0.1%の品質検査自動化において、最適なアプローチはどれですか？",
      "choices": [
        {
          "label": "A",
          "text": "通常の二値分類モデルを訓練"
        },
        {
          "label": "B",
          "text": "正常品のみでOne-Class SVMや異常検知モデルを訓練"
        },
        {
          "label": "C",
          "text": "不良品データを削除して良品のみで学習"
        },
        {
          "label": "D",
          "text": "画像認識は使用不可"
        }
      ],
      "correct": [1],
      "explanation": "<h5>詳細解説</h5><p>不良品率0.1%は極端な不均衡データです。通常の分類手法では、全て良品と予測するだけで精度99.9%となり、実用的ではありません。異常検知アプローチが必要です。</p><h5>異常検知手法の利点</h5><ul><li><strong>正常パターンの学習:</strong> 大量の良品データから正常の境界を定義</li><li><strong>未知の異常:</strong> 学習時に見たことのない新しい不良パターンも検出可能</li><li><strong>現実的なアプローチ:</strong> 製造現場の実際のデータ分布に適合</li></ul><h5>推奨手法</h5><ul><li><strong>One-Class SVM:</strong> 正常データの境界を学習</li><li><strong>オートエンコーダ:</strong> 正常品の再構成誤差で異常を検出</li><li><strong>Isolation Forest:</strong> 異常値の孤立性を利用</li></ul><h5>実装のコツ</h5><p>閾値調整、ドメイン知識との組み合わせ、段階的な導入で誤検知を最小化。</p>",
      "resources": []
    },
    {
      "id": "d1_q33",
      "type": "single",
      "text": "モデル選択でバイアス-バリアンス トレードオフを考慮する際、正しい理解はどれですか？",
      "choices": [
        {
          "label": "A",
          "text": "バイアスとバリアンスは同時に最小化可能"
        },
        {
          "label": "B",
          "text": "単純なモデルは高バイアス・低バリアンス、複雑なモデルは低バイアス・高バリアンス"
        },
        {
          "label": "C",
          "text": "バリアンスが高いほど常に良い"
        },
        {
          "label": "D",
          "text": "このトレードオフは実務で無視できる"
        }
      ],
      "correct": [1],
      "explanation": "<h5>詳細解説</h5><p>バイアス-バリアンス トレードオフは機械学習の根本的な制約で、モデル複雑さと汎化性能の関係を表します。期待誤差 = バイアス² + バリアンス + ノイズで分解できます。</p><h5>実際のトレードオフ</h5><ul><li><strong>線形回帰:</strong> 高バイアス（非線形関係を捉えられない）・低バリアンス（安定）</li><li><strong>深層NN:</strong> 低バイアス（複雑なパターンを学習）・高バリアンス（過学習リスク）</li><li><strong>最適点:</strong> 両者のバランスで総誤差を最小化</li></ul><h5>実務での対処法</h5><ul><li><strong>バイアス改善:</strong> モデル複雑化、特徴量追加、アンサンブル</li><li><strong>バリアンス改善:</strong> 正則化、データ増加、特徴選択</li><li><strong>両方改善:</strong> バギング、ブースティング</li></ul><h5>なぜ同時最小化は不可能か</h5><p>複雑さを上げるとバイアス↓・バリアンス↑、下げるとバイアス↑・バリアンス↓となるため。</p>",
      "resources": []
    },
    {
      "id": "d1_q34",
      "type": "single",
      "text": "自然言語処理で「word embedding（単語埋め込み）」が重要な理由は何ですか？",
      "choices": [
        {
          "label": "A",
          "text": "テキストデータを削除するため"
        },
        {
          "label": "B",
          "text": "単語間の意味的関係を密なベクトル空間で表現するため"
        },
        {
          "label": "C",
          "text": "文章を物理的に長くするため"
        },
        {
          "label": "D",
          "text": "文法エラーを自動修正するため"
        }
      ],
      "correct": [1],
      "explanation": "<h5>詳細解説</h5><p>Word embeddingは、単語をOne-hotエンコーディングの代わりに密なベクトルで表現し、意味的類似性を数値的に捉える技術です。</p><h5>埋め込みの利点</h5><ul><li><strong>意味的関係:</strong> 類似単語は近いベクトル（king - man + woman ≈ queen）</li><li><strong>次元効率:</strong> 語彙数万→数百次元への圧縮</li><li><strong>汎化性能:</strong> 学習データにない組み合わせも意味的に処理</li></ul><h5>主要な手法</h5><ul><li><strong>Word2Vec:</strong> 文脈から単語を予測（CBOW）、単語から文脈を予測（Skip-gram）</li><li><strong>GloVe:</strong> 共起行列の統計情報を活用</li><li><strong>BERT:</strong> 文脈依存の動的埋め込み</li></ul><h5>応用例</h5><p>機械翻訳、文書分類、質問応答、推薦システムなど。現代NLPの基盤技術。</p>",
      "resources": []
    },
    {
      "id": "d1_q35",
      "type": "single",
      "text": "機械学習モデルの性能が期待より低い場合、最も避けるべきデバッグ手法はどれですか？",
      "choices": [
        {
          "label": "A",
          "text": "学習曲線の分析"
        },
        {
          "label": "B",
          "text": "特徴量の重要度確認"
        },
        {
          "label": "C",
          "text": "テストデータでの訓練・パラメータ調整"
        },
        {
          "label": "D",
          "text": "誤分類サンプルの詳細分析"
        }
      ],
      "correct": [2],
      "explanation": "<h5>詳細解説</h5><p>テストデータでの訓練・調整は、データリーケージを引き起こし、汎化性能を過大評価する重大な誤りです。テストデータは最終評価にのみ使用すべきです。</p><h5>適切なデバッグプロセス</h5><ul><li><strong>A) 学習曲線:</strong> 過学習・未学習の診断、データ量の影響確認</li><li><strong>B) 特徴量重要度:</strong> どの特徴が予測に貢献しているか把握</li><li><strong>D) エラー分析:</strong> 誤分類パターンの特定、バイアス発見</li></ul><h5>正しいデータ分割</h5><ol><li><strong>訓練データ:</strong> モデル学習用</li><li><strong>検証データ:</strong> ハイパーパラメータ調整、モデル選択</li><li><strong>テストデータ:</strong> 最終評価のみ（1回限り使用）</li></ol><h5>その他のデバッグ手法</h5><p>クロスバリデーション、学習率・バッチサイズの調整、アーキテクチャの見直し、データ品質の確認。</p>",
      "resources": []
    },
    {
      "id": "d1_q36",
      "type": "single",
      "text": "Netflix等の動画配信サービスが「あなたへのおすすめ」を生成する際の中核技術はどれですか？",
      "choices": [
        {
          "label": "A",
          "text": "画像認識による映像解析"
        },
        {
          "label": "B",
          "text": "協調フィルタリングと時系列分析の組み合わせ"
        },
        {
          "label": "C",
          "text": "音声認識による字幕生成"
        },
        {
          "label": "D",
          "text": "自然言語生成による要約作成"
        }
      ],
      "correct": [1],
      "explanation": "<h5>詳細解説</h5><p>動画配信の推薦システムは、ユーザー間の視聴パターン類似性（協調フィルタリング）と時間的な視聴行動変化（時系列分析）を組み合わせて、個人化された推薦を実現します。</p><h5>協調フィルタリングの種類</h5><ul><li><strong>ユーザーベース:</strong> 類似ユーザーの視聴履歴から推薦</li><li><strong>アイテムベース:</strong> 視聴済み作品と類似した作品を推薦</li><li><strong>行列分解:</strong> ユーザー×作品の評価行列を低ランク近似</li></ul><h5>時系列分析の活用</h5><ul><li><strong>視聴パターン:</strong> 週末はアクション、平日はドラマなどの傾向</li><li><strong>季節性:</strong> ホラーは10月、ロマンスは2月に人気</li><li><strong>セッション情報:</strong> 連続視聴、時間帯による嗜好変化</li></ul><h5>実装のポイント</h5><p>暗黙的フィードバック（視聴時間、完了率）、コンテンツ特徴（ジャンル、出演者）、深層学習（Neural CF）の統合。</p>",
      "resources": []
    },
    {
      "id": "d1_q37",
      "type": "single",
      "text": "深層ニューラルネットワークの「勾配消失問題」を解決する手法として不適切なものはどれですか？",
      "choices": [
        {
          "label": "A",
          "text": "ReLU活性化関数の使用"
        },
        {
          "label": "B",
          "text": "バッチ正規化の導入"
        },
        {
          "label": "C",
          "text": "全層でシグモイド関数を使用"
        },
        {
          "label": "D",
          "text": "残差接続（ResNet）の実装"
        }
      ],
      "correct": [2],
      "explanation": "<h5>詳細解説</h5><p>シグモイド関数の全層使用は勾配消失問題を悪化させます。シグモイドの微分最大値は0.25で、深い層では勾配が指数関数的に減衰します。</p><h5>勾配消失の原因と対策</h5><ul><li><strong>問題:</strong> 逆伝播で勾配が層を通るたびに小さくなり、深い層の学習が停滞</li><li><strong>シグモイドの問題:</strong> 飽和領域で勾配≈0、連続的な掛け算で急速減衰</li></ul><h5>効果的な解決策</h5><ul><li><strong>A) ReLU:</strong> 正領域で勾配=1、勾配消失を大幅軽減</li><li><strong>B) バッチ正規化:</strong> 各層の入力を正規化、勾配の流れを改善</li><li><strong>D) 残差接続:</strong> スキップ接続で勾配が直接伝播、深いネットワークが可能</li></ul><h5>その他の対策</h5><p>He初期化、LSTM/GRUのゲート機構、Leaky ReLU、ELU等の改良活性化関数。</p>",
      "resources": []
    },
    {
      "id": "d1_q38",
      "type": "single",
      "text": "機械学習における「データリーケージ」の最も深刻な例はどれですか？",
      "choices": [
        {
          "label": "A",
          "text": "データの物理的な紛失"
        },
        {
          "label": "B",
          "text": "前処理時にテストデータの統計情報を使用"
        },
        {
          "label": "C",
          "text": "訓練データの量が少ない"
        },
        {
          "label": "D",
          "text": "計算処理が遅い"
        }
      ],
      "correct": [1],
      "explanation": "<h5>詳細解説</h5><p>データリーケージは、本来利用できない未来の情報やテストデータの情報が訓練に混入する現象で、モデルの性能を過大評価し、実運用で大幅な性能劣化を引き起こします。</p><h5>典型的なリーケージ例</h5><ul><li><strong>前処理リーケージ:</strong> 全データで正規化→テストの分布情報が訓練に混入</li><li><strong>時間的リーケージ:</strong> 株価予測で未来の価格情報が特徴量に含まれる</li><li><strong>ターゲットリーケージ:</strong> 予測対象と強相関だが実際は使えない特徴量</li></ul><h5>深刻な影響</h5><ul><li><strong>開発時:</strong> 精度99%の「奇跡的」な結果</li><li><strong>本番時:</strong> 精度60%に急落、プロジェクト失敗</li><li><strong>ビジネス:</strong> 期待とのギャップ、投資損失</li></ul><h5>防止策</h5><p>時系列での適切なデータ分割、パイプライン化、ドメイン知識による特徴量検証。</p>",
      "resources": []
    },
    {
      "id": "d1_q39",
      "type": "single",
      "text": "小規模データセットでモデル性能を正確に評価するための最適な手法はどれですか？",
      "choices": [
        {
          "label": "A",
          "text": "単一の訓練・テスト分割"
        },
        {
          "label": "B",
          "text": "k-fold クロスバリデーション"
        },
        {
          "label": "C",
          "text": "テストデータのみで評価"
        },
        {
          "label": "D",
          "text": "訓練データでの評価"
        }
      ],
      "correct": [1],
      "explanation": "<h5>詳細解説</h5><p>小規模データでは、単一分割だと評価の信頼性が低くなります。k-fold クロスバリデーションにより、全データを効率的に活用し、安定した性能評価が可能です。</p><h5>クロスバリデーションの利点</h5><ul><li><strong>データ効率:</strong> 全サンプルが訓練と検証両方に使用される</li><li><strong>評価安定性:</strong> k回の評価の平均と分散で信頼性向上</li><li><strong>偏り軽減:</strong> データ分割の偶然性の影響を最小化</li></ul><h5>実装のポイント</h5><ul><li><strong>k=5または10:</strong> バイアス-バリアンス バランスが良好</li><li><strong>Stratified k-fold:</strong> クラス不均衡データで各分割のクラス比を保持</li><li><strong>Time Series Split:</strong> 時系列データでは時間順を保持</li></ul><h5>なぜ他が不適切か</h5><p>A: 評価が不安定、C,D: 汎化性能を評価できない</p>",
      "resources": []
    },
    {
      "id": "d1_q40",
      "type": "single",
      "text": "株価や売上などの時系列予測に最も適したニューラルネットワークアーキテクチャはどれですか？",
      "choices": [
        {
          "label": "A",
          "text": "畳み込みニューラルネットワーク（CNN）"
        },
        {
          "label": "B",
          "text": "LSTM（Long Short-Term Memory）"
        },
        {
          "label": "C",
          "text": "多層パーセプトロン（MLP）"
        },
        {
          "label": "D",
          "text": "オートエンコーダ"
        }
      ],
      "correct": [1],
      "explanation": "<h5>詳細解説</h5><p>LSTMは時系列データの長期依存関係を学習できるRNNの改良版で、勾配消失問題を解決し、過去の重要な情報を選択的に保持・忘却できます。</p><h5>LSTMの優位性</h5><ul><li><strong>ゲート機構:</strong> 入力・忘却・出力ゲートで情報フローを制御</li><li><strong>長期記憶:</strong> 数百ステップ前の情報も活用可能</li><li><strong>柔軟性:</strong> トレンド、季節性、周期性を同時に学習</li></ul><h5>時系列予測での応用</h5><ul><li><strong>金融:</strong> 株価、為替レート、ボラティリティ予測</li><li><strong>需要予測:</strong> 小売売上、エネルギー消費量</li><li><strong>IoT:</strong> センサーデータ、異常検知</li></ul><h5>なぜ他が不適切か</h5><ul><li>A: CNNは空間的パターン用、時間的依存関係は苦手</li><li>C: MLPは時系列の順序情報を活用できない</li><li>D: オートエンコーダは圧縮・復元用、予測専用ではない</li></ul>",
      "resources": []
    }
  ]
}
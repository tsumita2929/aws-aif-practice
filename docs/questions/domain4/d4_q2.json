{
  "id": "d4_q2",
  "type": "single",
  "text": "あるEコマース企業が、商品推薦モデルの推論エンドポイントを運用しています。現在の状況：平均レスポンスタイム: 150ms（要件: <200ms）、ピーク時リクエスト: 10,000/分、オフピーク時リクエスト: 100/分、現在のコスト: $3,000/月（ml.m5.4xlarge × 3台固定）。最もコスト効率的な最適化戦略はどれですか？",
  "choices": [
    {
      "label": "A",
      "text": "Amazon Elastic Inferenceを追加し、GPUアクセラレーションでインスタンスサイズを削減"
    },
    {
      "label": "B",
      "text": "SageMaker Multi-Model Endpointで複数モデルを1つのエンドポイントに統合"
    },
    {
      "label": "C",
      "text": "Application Auto Scalingを設定し、最小1台、最大5台でTargetInvocationsPerInstance=1000に設定"
    },
    {
      "label": "D",
      "text": "SageMaker Serverless Inferenceに移行し、使用した分のみ課金"
    }
  ],
  "correct": [
    2
  ],
  "explanation": "\n                <h5>詳細解説</h5>\n                <p>トラフィックの変動が100倍あるため、Auto Scalingが最適です。</p>\n                <h5>コスト計算</h5>\n                <ul>\n                    <li><strong>現在:</strong> $3,000/月（固定3台）</li>\n                    <li><strong>Auto Scaling後:</strong>\n                        <ul>\n                            <li>ピーク時（8時間/日）: 3-5台 = $1,200/月</li>\n                            <li>オフピーク時（16時間/日）: 1台 = $400/月</li>\n                            <li>合計: 約$1,600/月（47%削減）</li>\n                        </ul>\n                    </li>\n                </ul>\n                <h5>実装例</h5>\n                <pre><code>response = client.put_scaling_policy(\n    PolicyName='TargetTracking',\n    TargetTrackingScalingPolicyConfiguration={\n        'TargetValue': 1000.0,\n        'PredefinedMetricType': 'SageMakerVariantInvocationsPerInstance'\n    }\n)</code></pre>\n            ",
  "resources": [
    {
      "title": "SageMaker Inference Cost Optimization",
      "url": "https://aws.amazon.com/blogs/machine-learning/"
    }
  ]
}
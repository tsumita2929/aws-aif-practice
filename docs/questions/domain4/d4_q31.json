{
  "id": "d4_q31",
  "type": "single",
  "text": "「モデルの解釈可能性」と「性能」のバランスを取る方法として適切なものはどれですか？",
  "choices": [
    {
      "label": "A",
      "text": "常に最も複雑なモデルを選ぶ"
    },
    {
      "label": "B",
      "text": "ユースケースに応じて適切なモデルを選択し、必要に応じて説明手法を追加"
    },
    {
      "label": "C",
      "text": "解釈可能性を完全に無視する"
    },
    {
      "label": "D",
      "text": "常に線形モデルのみを使用する"
    }
  ],
  "correct": [
    1
  ],
  "explanation": "<h5>詳細解説</h5><p>正解はB: ユースケースに応じて適切なモデルを選択し、必要に応じて説明手法を追加です。</p><p>解釈可能性と性能のバランスは、MLプロジェクトの成功において重要な要素です。ユースケースの要件に基づいて、適切なトレードオフを見つけることが必要です。</p><h5>各選択肢の解説</h5><p>A) 常に最も複雑なモデルを選ぶ - これは誤りです。複雑なモデルは解釈が困難で、規制要件や説明責任を満たせない場合があります。</p><h5>B) ユースケースに応じて適切なモデルを選択し、必要に応じて説明手法を追加（正解）- バランスの取れたアプローチ</h5><ul><li>ユースケース別の戦略：</li><li>医療診断：解釈可能性を優先（決定木、線形モデル）</li><li>画像認識：性能を優先し、説明手法を追加（Grad-CAM）</li><li>金融審査：規制要件に応じてバランス</li><li>推薦システム：性能重視でも許容される場合が多い</li><li>ハイブリッドアプローチ：</li><li>複雑なモデル＋事後説明（SHAP、LIME）</li><li>アンサンブル：解釈可能モデルと高性能モデルの組み合わせ</li><li>階層的モデリング：重要な決定は解釈可能モデル</li><li>代理モデル：複雑なモデルの振る舞いを簡単なモデルで近似</li><li>説明手法の追加：</li><li>グローバル説明：モデル全体の動作</li><li>ローカル説明：個別予測の根拠</li><li>反実仮想説明：「もし〜だったら」</li><li>特徴重要度の可視化</li></ul><p>C) 解釈可能性を完全に無視する - 規制違反、信頼性の欠如、デバッグの困難さにつながります。</p><p>D) 常に線形モデルのみを使用する - 複雑な問題では性能が不十分になり、ビジネス価値を損ないます。</p><h5>実践例：クレジットスコアリングシステムの実装</h5><h5>1. 要件分析</h5><ul><li>規制要件：説明可能性が必須（FCRA、ECOA）</li><li>性能要件：AUC > 0.85</li><li>ビジネス要件：処理時間 < 100ms</li></ul><h5>2. モデル選択戦略</h5><p>```python</p><p># 階層的アプローチ</p><h5>class CreditScoringSystem</h5><h5>def __init__(self)</h5><p># 第1層：解釈可能なルールベース</p><p>self.rule_based = DecisionTreeClassifier(max_depth=5)</p><p># 第2層：中程度の複雑性</p><p>self.gradient_boost = XGBoostClassifier()</p><p># 説明生成器</p><p>self.explainer = shap.TreeExplainer(self.gradient_boost)</p><p>```</p><h5>3. 説明性の実装</h5><ul><li>ルールの抽出と可視化</li><li>拒否理由コードの生成</li><li>個別説明レポート</li><li>監査証跡の保持</li></ul><h5>4. 性能と解釈性の評価</h5><ul><li>線形モデル：AUC=0.75、完全に解釈可能</li><li>決定木：AUC=0.80、ルールベースで理解可能</li><li>XGBoost+SHAP：AUC=0.88、事後説明付き</li><li>選択：XGBoost+SHAP（要件を満たす）</li></ul><h5>成果</h5><ul><li>規制要件準拠：100%</li><li>モデル性能：AUC=0.88</li><li>顧客満足度：説明付き判定で30%向上</li><li>監査合格率：100%</li></ul><p>このアプローチにより、高性能と説明可能性を両立させることができます。</p><h5>なぜ他の選択肢が間違っているのか</h5><ul><li><strong>A) 常に最も複雑なモデルを選ぶ:</strong> 再現性は科学的検証とデバッグのために重要で、省略すべきではありません。</li><li><strong>C) 解釈可能性を完全に無視する:</strong> ベースラインとの比較なしには、提案手法の有効性を適切に評価できません。</li><li><strong>D) 常に線形モデルのみを使用する:</strong> 定性的評価も重要ですが、定量的評価と組み合わせる必要があります。</li></ul>",
  "resources": []
}
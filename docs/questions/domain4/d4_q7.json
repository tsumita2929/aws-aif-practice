{
  "id": "d4_q7",
  "type": "single",
  "text": "モデルの性能評価において、訓練データとテストデータを分割する一般的な比率はどれですか？",
  "choices": [
    {
      "label": "A",
      "text": "50:50"
    },
    {
      "label": "B",
      "text": "80:20 または 70:30"
    },
    {
      "label": "C",
      "text": "95:5"
    },
    {
      "label": "D",
      "text": "10:90"
    }
  ],
  "correct": [
    1
  ],
  "explanation": "<h5>詳細解説</h5><p>正解はB: 80:20 または 70:30です。</p><p>機械学習モデルの性能評価において、データの分割は非常に重要です。一般的には、訓練データ80%、テストデータ20%、または訓練データ70%、テストデータ30%の比率が最も一般的に使用されます。</p><h5>各選択肢の解説</h5><p>A) 50:50 - この比率では訓練データが少なすぎて、モデルが十分に学習できない可能性があります。特にディープラーニングモデルの場合、大量の訓練データが必要となります。</p><p>B) 80:20 または 70:30（正解）- これらの比率はバランスが良く、モデルの学習に十分なデータを確保しつつ、信頼性のある評価を行うための十分なテストデータも確保できます。多くの機械学習フレームワーク（scikit-learnなど）でもデフォルト値として採用されています。</p><p>C) 95:5 - テストデータが極端に少なく、モデルの汎化性能を正確に評価できません。テストデータが少なすぎると、統計的に信頼性のある評価が難しくなります。</p><p>D) 10:90 - 訓練データが少なすぎて、モデルがパターンを学習するのに不十分です。これではアンダーフィッティングのリスクが高まります。</p><p>実践的な使用例：Amazon SageMakerでは、データ分割を自動化する機能が提供されています。さらに、クロスバリデーションを使用する場合は、データを複数のフォールドに分割してより堅牢な評価を行うこともできます。データセットのサイズやタスクの複雑さに応じて、適切な分割戦略を選択することが重要です。</p><h5>なぜ他の選択肢が間違っているのか</h5><ul><li><strong>C) 95:5:</strong> Fine-tuningは追加の計算リソースを必要とするため、コスト削減にはつながりません。</li><li><strong>D) 10:90:</strong> Fine-tuningは追加のデータとトレーニングが必要なため、実装の複雑さはむしろ増加します。</li></ul>",
  "resources": []
}
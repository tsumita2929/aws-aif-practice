{
  "id": "d4_q13",
  "type": "single",
  "text": "Amazon SageMakerでのモデルのA/Bテストを実装する際の利点は何ですか？",
  "choices": [
    {
      "label": "A",
      "text": "開発時間を延長できる"
    },
    {
      "label": "B",
      "text": "新旧モデルの性能を本番環境で安全に比較できる"
    },
    {
      "label": "C",
      "text": "コストが増加する"
    },
    {
      "label": "D",
      "text": "データの品質が低下する"
    }
  ],
  "correct": [
    1
  ],
  "explanation": "<h5>詳細解説</h5><p>正解はB: 新旧モデルの性能を本番環境で安全に比較できるです。</p><p>A/Bテストは、新しいモデルを本番環境に安全にデプロイし、既存モデルと比較するための強力な手法です。Amazon SageMakerでは、トラフィックを分割して複数のモデルを同時にテストできます。</p><h5>各選択肢の解説</h5><p>A) 開発時間を延長できる - これは誤りです。A/Bテストは初期設定に時間がかかるかもしれませんが、長期的にはリスクを減らし、デプロイメントを加速します。</p><h5>B) 新旧モデルの性能を本番環境で安全に比較できる（正解）- A/Bテストの主な利点</h5><ul><li>実際のユーザートラフィックでモデルを評価</li><li>トラフィックの一部のみを新モデルに向けることでリスクを最小化</li><li>ビジネスメトリクス（コンバージョン率、売上など）での評価が可能</li><li>問題が発生した場合の迅速なロールバック</li></ul><p>C) コストが増加する - 短期的には複数モデルの同時実行によるコスト増がありますが、不適切なモデルのデプロイによるビジネス損失を避けることで、全体的なコストを削減できます。</p><p>D) データの品質が低下する - これは誤りです。A/Bテストはデータの品質に影響を与えません。同じ入力データを異なるモデルで処理するだけです。</p><p>実践例：NetflixやAmazonなどの大手テック企業では、推薦アルゴリズムの改善においてA/Bテストを幅広く活用しています。SageMakerのエンドポイント設定では、トラフィックの割合を細かく調整し、モデルのパフォーマンスを比較できます。たとえば、最初は5%のトラフィックから始め、問題がなければ徐々に割合を増やしていく「カナリアデプロイメント」が可能です。</p><h5>なぜ他の選択肢が間違っているのか</h5><ul><li><strong>A) 開発時間を延長できる:</strong> エラー処理だけでは根本的な問題解決にならず、モデルの改善が必要です。</li><li><strong>C) コストが増加する:</strong> ハードウェアの追加は精度の問題を解決しません。モデル自体の改善が必要です。</li></ul>",
  "resources": []
}
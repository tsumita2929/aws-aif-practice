{
  "id": "d4_q18",
  "type": "single",
  "text": "データパイプラインの設計において最も重要な原則はどれですか？",
  "choices": [
    {
      "label": "A",
      "text": "複雑性を最大化する"
    },
    {
      "label": "B",
      "text": "再現性、スケーラビリティ、エラーハンドリング"
    },
    {
      "label": "C",
      "text": "手動プロセスを増やす"
    },
    {
      "label": "D",
      "text": "ドキュメント化を避ける"
    }
  ],
  "correct": [
    1
  ],
  "explanation": "正解はB: 再現性、スケーラビリティ、エラーハンドリングです。\n\nデータパイプラインは機械学習システムの基盤であり、その設計品質がシステム全体の信頼性と効率性を決定します。堅牢なデータパイプラインは、データの収集から前処理、変換、保存まで一貫した処理を保証します。\n\n各選択肢の解説：\nA) 複雑性を最大化する - これは完全に誤りです。シンプルで理解しやすいパイプラインの方が、メンテナンスが容易で、エラーの発見と修正が迅速に行えます。\n\nB) 再現性、スケーラビリティ、エラーハンドリング（正解）- データパイプラインの三大原則：\n  ・再現性：同じ入力から常に同じ出力を生成\n    - データのバージョン管理\n    - 処理ロジックの明確な定義\n    - ランダムシードの固定\n  ・スケーラビリティ：データ量の増加に対応\n    - 並列処理の実装\n    - リソースの動的割り当て\n    - ボトルネックの特定と解消\n  ・エラーハンドリング：障害からの回復\n    - リトライ機構\n    - デッドレターキュー\n    - アラートとモニタリング\n\nC) 手動プロセスを増やす - これは避けるべきです。手動プロセスは人的エラーの原因となり、スケーラビリティを阻害します。\n\nD) ドキュメント化を避ける - データパイプラインの複雑性を考えると、ドキュメント化は必須です。データソース、変換ロジック、依存関係を明確に記録する必要があります。\n\n実践例：Amazon EMRとAWS Glueを使用したデータパイプライン：\n1. データ収集：Amazon Kinesisでリアルタイムストリーミング\n2. 前処理：AWS Glue ETLジョブで自動化\n3. 保存：S3にパーティション化して保存\n4. モニタリング：CloudWatchでメトリクス監視\n5. エラー処理：Step Functionsで復旧ワークフロー\n\nベストプラクティス：\n・Infrastructure as Code（Terraform/CloudFormation）\n・データ品質チェックの自動化\n・段階的なロールアウト（開発→ステージング→本番）\n・データリネージの追跡",
  "resources": []
}
{
  "id": "d4_q8",
  "type": "single",
  "text": "次のシナリオを考えてください： 「ECサイトでリアルタイムな商品推薦を実装したいが、レスポンス時間は100ms以内に抑える必要がある」 最も適切なデプロイメント戦略はどれですか？",
  "choices": [
    {
      "label": "A",
      "text": "バッチ推論のみを使用"
    },
    {
      "label": "B",
      "text": "エッジデバイスでの推論とキャッシング戦略の組み合わせ"
    },
    {
      "label": "C",
      "text": "全ての計算をクライアント側で実行"
    },
    {
      "label": "D",
      "text": "精度を犠牲にせず、最も複雑なモデルを使用"
    }
  ],
  "correct": [
    1
  ],
  "explanation": "<h5>詳細解説</h5><p>正解はB: エッジデバイスでの推論とキャッシング戦略の組み合わせです。</p><p>リアルタイムな商品推薦で100ms以内のレスポンス時間を実現するには、レイテンシーを最小化するアーキテクチャが必要です。エッジデバイスでの推論とキャッシングの組み合わせは、この要件を満たす最も効果的なアプローチです。</p><h5>各選択肢の解説</h5><p>A) バッチ推論のみを使用 - バッチ処理は大量のデータをまとめて処理するため、リアルタイムの要件には適しません。バッチ処理は通常、定期的な分析やレポート作成に適しています。</p><h5>B) エッジデバイスでの推論とキャッシング戦略の組み合わせ（正解）- このアプローチには以下の利点があります</h5><ul><li>エッジデバイス（CloudFrontのEdge LocationやAmazon SageMaker Edgeなど）で推論を実行することで、ネットワークレイテンシーを大幅に削減</li><li>高頻度の推薦結果をAmazon ElastiCacheやDynamoDBにキャッシュし、再計算を回避</li><li>モデルの軽量化（量子化、プルーニングなど）を組み合わせてさらに高速化</li></ul><p>C) 全ての計算をクライアント側で実行 - クライアントデバイスの性能は様々であり、複雑なモデルを実行するには不適切です。また、モデルの更新や管理が困難になります。</p><p>D) 精度を犠牲にせず、最も複雑なモデルを使用 - 複雑なモデルは推論時間が長くなるため、100ms以内のレスポンスを実現することは難しいです。実用的な解決策は、精度と速度のバランスを取ることです。</p><p>実践例：Amazonの商品推薦システムでは、Amazon Personalizeを使用してリアルタイム推薦を実現し、CloudFrontやElastiCacheを組み合わせてレイテンシーを最小化しています。また、SageMaker Neoを使用してモデルを最適化し、エッジデバイスでの高速推論を実現することも可能です。</p><h5>なぜ他の選択肢が間違っているのか</h5><ul><li><strong>A) バッチ推論のみを使用:</strong> 本番環境の変更は慎重に計画すべきで、まず開発・ステージング環境でテストを行うべきです。</li><li><strong>D) 精度を犠牲にせず、最も複雑なモデルを使用:</strong> ドキュメントの更新は重要ですが、それだけでは実際のデプロイメントプロセスは改善されません。</li></ul>",
  "resources": []
}
{
  "domain": 4,
  "group": 1,
  "title": "データ準備・最適化",
  "description": "データ品質評価、コスト最適化、MLOps、データドリフト、モデル評価、リアルタイム推論",
  "questionCount": 10,
  "questions": [
    {
      "id": "d4_q1",
      "type": "single",
      "text": "機械学習プロジェクトにおけるデータ準備の段階で最も重要なステップはどれですか？",
      "choices": [
        {
          "label": "A",
          "text": "すぐにモデルの学習を開始する"
        },
        {
          "label": "B",
          "text": "データの品質評価と欠損値の処理"
        },
        {
          "label": "C",
          "text": "最も複雑なアルゴリズムを選択する"
        },
        {
          "label": "D",
          "text": "ハードウェアのアップグレード"
        }
      ],
      "correct": [
        1
      ],
      "explanation": "\n                <h5>詳細解説</h5>\n                <p>データの品質がMLモデルの性能を大きく左右します。「Garbage In, Garbage Out」の原則が適用されます。</p>\n                <h5>データ準備の重要ステップ</h5>\n                <ul>\n                    <li><strong>データ品質評価:</strong> 完全性、一貫性、正確性のチェック</li>\n                    <li><strong>欠損値処理:</strong> 削除、補完、特殊値での置換</li>\n                    <li><strong>外れ値検出:</strong> 統計的手法やドメイン知識による判定</li>\n                    <li><strong>データ型の確認:</strong> 数値、カテゴリカル、日時データの適切な処理</li>\n                </ul>\n            <h5>なぜ他の選択肢が間違っているのか</h5><ul><li><strong>A) すぐにモデルの学習を開始する:</strong> データ準備を省略して学習を開始すると、品質の低いデータでモデルが学習され、精度の低い結果につながります。データ準備は機械学習プロジェクトの成功に不可欠です。</li><li><strong>C) 最も複雑なアルゴリズムを選択する:</strong> 複雑なアルゴリズムの選択はデータ準備の後に行うべきステップです。また、単純なアルゴリズムでも高品質なデータがあれば良い結果が得られることが多いです。</li><li><strong>D) ハードウェアのアップグレード:</strong> ハードウェアのアップグレードはパフォーマンス向上に役立ちますが、データ準備段階での最重要事項ではありません。まずはデータの品質確保が優先されます。</li></ul>",
      "resources": []
    },
    {
      "id": "d4_q2",
      "type": "single",
      "text": "あるEコマース企業が、商品推薦モデルの推論エンドポイントを運用しています。現在の状況：平均レスポンスタイム: 150ms（要件: <200ms）、ピーク時リクエスト: 10,000/分、オフピーク時リクエスト: 100/分、現在のコスト: $3,000/月（ml.m5.4xlarge × 3台固定）。最もコスト効率的な最適化戦略はどれですか？",
      "choices": [
        {
          "label": "A",
          "text": "Amazon Elastic Inferenceを追加し、GPUアクセラレーションでインスタンスサイズを削減"
        },
        {
          "label": "B",
          "text": "SageMaker Multi-Model Endpointで複数モデルを1つのエンドポイントに統合"
        },
        {
          "label": "C",
          "text": "Application Auto Scalingを設定し、最小1台、最大5台でTargetInvocationsPerInstance=1000に設定"
        },
        {
          "label": "D",
          "text": "SageMaker Serverless Inferenceに移行し、使用した分のみ課金"
        }
      ],
      "correct": [
        2
      ],
      "explanation": "\n                <h5>詳細解説</h5>\n                <p>トラフィックの変動が100倍あるため、Auto Scalingが最適です。</p>\n                <h5>コスト計算</h5>\n                <ul>\n                    <li><strong>現在:</strong> $3,000/月（固定3台）</li>\n                    <li><strong>Auto Scaling後:</strong>\n                        <ul>\n                            <li>ピーク時（8時間/日）: 3-5台 = $1,200/月</li>\n                            <li>オフピーク時（16時間/日）: 1台 = $400/月</li>\n                            <li>合計: 約$1,600/月（47%削減）</li>\n                        </ul>\n                    </li>\n                </ul>\n                <h5>実装例</h5>\n                <pre><code>response = client.put_scaling_policy(\n    PolicyName='TargetTracking',\n    TargetTrackingScalingPolicyConfiguration={\n        'TargetValue': 1000.0,\n        'PredefinedMetricType': 'SageMakerVariantInvocationsPerInstance'\n    }\n)</code></pre>\n            <h5>なぜ他の選択肢が間違っているのか</h5><ul><li><strong>A) Amazon Elastic Inferenceを追加し、GPUアクセラレーションでインスタンスサイズを削減:</strong> Elastic Inferenceは深層学習モデルに有効ですが、この場合150msで要件を満たしており、主な課題はトラフィック変動への対応とコスト削減です。</li><li><strong>B) SageMaker Multi-Model Endpointで複数モデルを1つのエンドポイントに統合:</strong> Multi-Model Endpointは単一モデルの場合には適用できません。複数のモデルを運用している場合に有効な手法です。</li><li><strong>D) SageMaker Serverless Inferenceに移行し、使用した分のみ課金:</strong> Serverless Inferenceは低頻度リクエストに適していますが、ピーク時10,000リクエスト/分では冷間起動の影響でレスポンス要件を満たせない可能性があります。</li></ul>",
      "resources": [
        {
          "title": "SageMaker Inference Cost Optimization",
          "url": "https://aws.amazon.com/blogs/machine-learning/"
        }
      ]
    },
    {
      "id": "d4_q3",
      "type": "multiple",
      "text": "MLシステムのコスト最適化において重要な要素を2つ選択してください。",
      "choices": [
        {
          "label": "A",
          "text": "SageMakerのスポットインスタンスを訓練に活用"
        },
        {
          "label": "B",
          "text": "推論エンドポイントの使用率に基づく自動スケーリング"
        },
        {
          "label": "C",
          "text": "常に最大のインスタンスタイプを使用"
        },
        {
          "label": "D",
          "text": "データを無期限に保存"
        },
        {
          "label": "E",
          "text": "全ての実験を本番環境で実施"
        }
      ],
      "correct": [
        0,
        1
      ],
      "explanation": "\n                <h5>詳細解説</h5>\n                <p>MLシステムのコスト最適化は、訓練と推論の両方で重要です。</p>\n                <h5>コスト最適化戦略</h5>\n                <ul>\n                    <li><strong>A: スポットインスタンス</strong>\n                        <ul>\n                            <li>訓練コストを最大90%削減</li>\n                            <li>チェックポイント機能で中断に対応</li>\n                            <li>本番推論には不適</li>\n                        </ul>\n                    </li>\n                    <li><strong>B: 自動スケーリング</strong>\n                        <ul>\n                            <li>需要に応じたリソース調整</li>\n                            <li>過剰プロビジョニングの回避</li>\n                            <li>レスポンスタイムの維持</li>\n                        </ul>\n                    </li>\n                </ul>\n            <h5>なぜ他の選択肢が間違っているのか</h5><ul><li><strong>C) 常に最大のインスタンスタイプを使用:</strong> コスト最適化には適切なリソース選択が重要で、過剰なリソースは無駄になります。</li><li><strong>D) データを無期限に保存:</strong> この選択肢はコスト最適化に寄与しません。</li><li><strong>E) 全ての実験を本番環境で実施:</strong> この選択肢はコスト最適化に寄与しません。</li></ul>",
      "resources": []
    },
    {
      "id": "d4_q4",
      "type": "single",
      "text": "継続的な機械学習（MLOps）の実践において重要な要素として適切でないものはどれですか？",
      "choices": [
        {
          "label": "A",
          "text": "モデルのバージョン管理"
        },
        {
          "label": "B",
          "text": "自動化されたテストパイプライン"
        },
        {
          "label": "C",
          "text": "手動でのデプロイメントプロセス"
        },
        {
          "label": "D",
          "text": "パフォーマンスメトリクスの継続的モニタリング"
        }
      ],
      "correct": [
        2
      ],
      "explanation": "\n                <h5>詳細解説</h5>\n                <p>MLOpsでは自動化が重要です。手動デプロイメントは効率とエラー率の観点から避けるべきです。</p>\n                <h5>MLOpsの主要コンポーネント</h5>\n                <ul>\n                    <li><strong>バージョン管理:</strong> コード、データ、モデルの追跡</li>\n                    <li><strong>CI/CDパイプライン:</strong> 自動テストとデプロイ</li>\n                    <li><strong>モニタリング:</strong> モデルドリフト、性能劣化の検出</li>\n                    <li><strong>実験管理:</strong> ハイパーパラメータと結果の記録</li>\n                </ul>\n                <h5>自動化のメリット</h5>\n                <ul>\n                    <li>人的エラーの削減</li>\n                    <li>デプロイ時間の短縮</li>\n                    <li>再現性の確保</li>\n                </ul>\n            <h5>なぜ他の選択肢が間違っているのか</h5><ul><li><strong>A) モデルのバージョン管理:</strong> モデルのバージョン管理はMLOpsの重要な要素です。コード、データ、モデルの変更を追跡し、再現性を確保するために不可欠です。</li><li><strong>B) 自動化されたテストパイプライン:</strong> 自動化されたテストパイプラインはMLOpsの中核です。モデルの品質を継続的に検証し、問題を早期に発見できます。</li><li><strong>D) パフォーマンスメトリクスの継続的モニタリング:</strong> パフォーマンスメトリクスの継続的モニタリングは、モデルドリフトや性能劣化を検出するために必須です。</li></ul>",
      "resources": []
    },
    {
      "id": "d4_q5",
      "type": "single",
      "text": "データドリフトが発生した場合の対処法として最も適切なものはどれですか？",
      "choices": [
        {
          "label": "A",
          "text": "既存のモデルをそのまま使い続ける"
        },
        {
          "label": "B",
          "text": "新しいデータでモデルを再訓練する"
        },
        {
          "label": "C",
          "text": "システムを完全に停止する"
        },
        {
          "label": "D",
          "text": "より多くのハードウェアリソースを追加する"
        }
      ],
      "correct": [
        1
      ],
      "explanation": "\n                <h5>詳細解説</h5>\n                <p>データドリフトは、時間経過によるデータ分布の変化です。新しいデータでの再訓練が必要です。</p>\n                <h5>データドリフトへの対応プロセス</h5>\n                <ol>\n                    <li><strong>検出:</strong> 統計的検定、分布の可視化</li>\n                    <li><strong>評価:</strong> モデル性能への影響度測定</li>\n                    <li><strong>対処:</strong> 再訓練、特徴量の調整</li>\n                    <li><strong>検証:</strong> 新モデルの性能確認</li>\n                </ol>\n                <h5>予防策</h5>\n                <ul>\n                    <li>定期的な再訓練スケジュール</li>\n                    <li>オンライン学習の実装</li>\n                    <li>モニタリングの自動化</li>\n                </ul>\n            <h5>なぜ他の選択肢が間違っているのか</h5><ul><li><strong>A) 既存のモデルをそのまま使い続ける:</strong> プリセットモデルは便利ですが、すべてのユースケースに適しているわけではなく、特定の要件に合わせたカスタマイズが必要な場合があります。</li><li><strong>C) システムを完全に停止する:</strong> モデルのサイズは精度と直接的な相関関係がありません。適切なサイズのモデルが最良の結果をもたらすことがあります。</li><li><strong>D) より多くのハードウェアリソースを追加する:</strong> 複雑なモデルは必ずしも単純なモデルより優れているわけではありません。タスクに適したモデルの選択が重要です。</li></ul>",
      "resources": []
    },
    {
      "id": "d4_q6",
      "type": "single",
      "text": "機械学習プロジェクトにおけるデータ準備の段階で最も重要なステップはどれですか？",
      "choices": [
        {
          "label": "A",
          "text": "すぐにモデルの学習を開始する"
        },
        {
          "label": "B",
          "text": "データの品質評価と欠損値の処理"
        },
        {
          "label": "C",
          "text": "最も複雑なアルゴリズムを選択する"
        },
        {
          "label": "D",
          "text": "ハードウェアのアップグレード"
        }
      ],
      "correct": [
        1
      ],
      "explanation": "<h5>詳細解説</h5><p>正解はB: データの品質評価と欠損値の処理です。</p><p>機械学習プロジェクトの成功は、データの品質に大きく依存します。『Garbage In, Garbage Out』という言葉があるように、質の低いデータからは質の低い予測しか得られません。</p><h5>各選択肢の解説</h5><p>A) すぐにモデルの学習を開始する - データの品質を確認せずに学習を開始すると、欠損値やノイズ、外れ値などの問題により、モデルの性能が大幅に低下する可能性があります。</p><p>B) データの品質評価と欠損値の処理（正解）- これは機械学習プロジェクトの基礎となる重要なステップです。データの統計的特性を理解し、欠損値の処理方法（削除、補完、特殊値での置換など）を適切に選択することで、モデルの性能を最大化できます。</p><p>C) 最も複雑なアルゴリズムを選択する - データの準備が不十分な状態で複雑なアルゴリズムを使用しても、良い結果は得られません。シンプルなモデルでも、適切に準備されたデータがあれば優れた性能を発揮できます。</p><p>D) ハードウェアのアップグレード - ハードウェアは処理速度を向上させますが、データの品質問題を解決することはできません。</p><p>実践例：Amazon SageMakerのData Wranglerを使用すると、データの品質評価、欠損値の可視化、異常値の検出などを効率的に行うことができます。これにより、データサイエンティストは本来の分析作業により多くの時間を割くことができます。</p><h5>なぜ他の選択肢が間違っているのか</h5><ul><li><strong>A) すぐにモデルの学習を開始する:</strong> ラベル付きデータが入手可能な場合、教師ありアプローチの方が一般的に高い精度が得られます。教師なし学習は主にラベルがない場合に使用されます。</li><li><strong>C) 最も複雑なアルゴリズムを選択する:</strong> 転移学習はラベル付きデータが少ない場合に有効ですが、十分なラベル付きデータがある場合は、タスク特化型モデルの方が良い結果が得られることがあります。</li><li><strong>D) ハードウェアのアップグレード:</strong> 半教師あり学習は限られたラベル付きデータを補完するために使用されますが、十分なラベル付きデータがある場合は必要ありません。</li></ul>",
      "resources": []
    },
    {
      "id": "d4_q7",
      "type": "single",
      "text": "モデルの性能評価において、訓練データとテストデータを分割する一般的な比率はどれですか？",
      "choices": [
        {
          "label": "A",
          "text": "50:50"
        },
        {
          "label": "B",
          "text": "80:20 または 70:30"
        },
        {
          "label": "C",
          "text": "95:5"
        },
        {
          "label": "D",
          "text": "10:90"
        }
      ],
      "correct": [
        1
      ],
      "explanation": "<h5>詳細解説</h5><p>正解はB: 80:20 または 70:30です。</p><p>機械学習モデルの性能評価において、データの分割は非常に重要です。一般的には、訓練データ80%、テストデータ20%、または訓練データ70%、テストデータ30%の比率が最も一般的に使用されます。</p><h5>各選択肢の解説</h5><p>A) 50:50 - この比率では訓練データが少なすぎて、モデルが十分に学習できない可能性があります。特にディープラーニングモデルの場合、大量の訓練データが必要となります。</p><p>B) 80:20 または 70:30（正解）- これらの比率はバランスが良く、モデルの学習に十分なデータを確保しつつ、信頼性のある評価を行うための十分なテストデータも確保できます。多くの機械学習フレームワーク（scikit-learnなど）でもデフォルト値として採用されています。</p><p>C) 95:5 - テストデータが極端に少なく、モデルの汎化性能を正確に評価できません。テストデータが少なすぎると、統計的に信頼性のある評価が難しくなります。</p><p>D) 10:90 - 訓練データが少なすぎて、モデルがパターンを学習するのに不十分です。これではアンダーフィッティングのリスクが高まります。</p><p>実践的な使用例：Amazon SageMakerでは、データ分割を自動化する機能が提供されています。さらに、クロスバリデーションを使用する場合は、データを複数のフォールドに分割してより堅牢な評価を行うこともできます。データセットのサイズやタスクの複雑さに応じて、適切な分割戦略を選択することが重要です。</p><h5>なぜ他の選択肢が間違っているのか</h5><ul><li><strong>C) 95:5:</strong> Fine-tuningは追加の計算リソースを必要とするため、コスト削減にはつながりません。</li><li><strong>D) 10:90:</strong> Fine-tuningは追加のデータとトレーニングが必要なため、実装の複雑さはむしろ増加します。</li></ul>",
      "resources": []
    },
    {
      "id": "d4_q8",
      "type": "single",
      "text": "次のシナリオを考えてください： 「ECサイトでリアルタイムな商品推薦を実装したいが、レスポンス時間は100ms以内に抑える必要がある」 最も適切なデプロイメント戦略はどれですか？",
      "choices": [
        {
          "label": "A",
          "text": "バッチ推論のみを使用"
        },
        {
          "label": "B",
          "text": "エッジデバイスでの推論とキャッシング戦略の組み合わせ"
        },
        {
          "label": "C",
          "text": "全ての計算をクライアント側で実行"
        },
        {
          "label": "D",
          "text": "精度を犠牲にせず、最も複雑なモデルを使用"
        }
      ],
      "correct": [
        1
      ],
      "explanation": "<h5>詳細解説</h5><p>正解はB: エッジデバイスでの推論とキャッシング戦略の組み合わせです。</p><p>リアルタイムな商品推薦で100ms以内のレスポンス時間を実現するには、レイテンシーを最小化するアーキテクチャが必要です。エッジデバイスでの推論とキャッシングの組み合わせは、この要件を満たす最も効果的なアプローチです。</p><h5>各選択肢の解説</h5><p>A) バッチ推論のみを使用 - バッチ処理は大量のデータをまとめて処理するため、リアルタイムの要件には適しません。バッチ処理は通常、定期的な分析やレポート作成に適しています。</p><h5>B) エッジデバイスでの推論とキャッシング戦略の組み合わせ（正解）- このアプローチには以下の利点があります</h5><ul><li>エッジデバイス（CloudFrontのEdge LocationやAmazon SageMaker Edgeなど）で推論を実行することで、ネットワークレイテンシーを大幅に削減</li><li>高頻度の推薦結果をAmazon ElastiCacheやDynamoDBにキャッシュし、再計算を回避</li><li>モデルの軽量化（量子化、プルーニングなど）を組み合わせてさらに高速化</li></ul><p>C) 全ての計算をクライアント側で実行 - クライアントデバイスの性能は様々であり、複雑なモデルを実行するには不適切です。また、モデルの更新や管理が困難になります。</p><p>D) 精度を犠牲にせず、最も複雑なモデルを使用 - 複雑なモデルは推論時間が長くなるため、100ms以内のレスポンスを実現することは難しいです。実用的な解決策は、精度と速度のバランスを取ることです。</p><p>実践例：Amazonの商品推薦システムでは、Amazon Personalizeを使用してリアルタイム推薦を実現し、CloudFrontやElastiCacheを組み合わせてレイテンシーを最小化しています。また、SageMaker Neoを使用してモデルを最適化し、エッジデバイスでの高速推論を実現することも可能です。</p><h5>なぜ他の選択肢が間違っているのか</h5><ul><li><strong>A) バッチ推論のみを使用:</strong> 本番環境の変更は慎重に計画すべきで、まず開発・ステージング環境でテストを行うべきです。</li><li><strong>D) 精度を犠牲にせず、最も複雑なモデルを使用:</strong> ドキュメントの更新は重要ですが、それだけでは実際のデプロイメントプロセスは改善されません。</li></ul>",
      "resources": []
    },
    {
      "id": "d4_q9",
      "type": "single",
      "text": "機械学習モデルのモニタリングで重要な指標として適切でないものはどれですか？",
      "choices": [
        {
          "label": "A",
          "text": "予測精度の経時変化"
        },
        {
          "label": "B",
          "text": "推論レイテンシー"
        },
        {
          "label": "C",
          "text": "ソースコードの行数"
        },
        {
          "label": "D",
          "text": "データドリフトの検出"
        }
      ],
      "correct": [
        2
      ],
      "explanation": "<h5>詳細解説</h5><p>正解はC: ソースコードの行数です。</p><p>機械学習モデルのモニタリングは、モデルが本番環境で期待どおりの性能を維持しているかを確認するために重要です。ソースコードの行数は、モデルの性能や信頼性とは直接的な関係がありません。</p><h5>各選択肢の解説</h5><p>A) 予測精度の経時変化 - これは非常に重要な指標です。時間の経過とともにモデルの精度が低下する「モデルドリフト」を検出できます。Amazon SageMaker Model Monitorでは、この指標を自動的に追跡できます。</p><p>B) 推論レイテンシー - リアルタイムアプリケーションでは特に重要です。レイテンシーが増加すると、ユーザーエクスペリエンスが悪化し、SLA違反につながる可能性があります。</p><p>C) ソースコードの行数（正解）- コードの行数はモデルの品質や性能を示す指標ではありません。シンプルなモデルが優れた性能を発揮することはよくあり、コードの量よりも質が重要です。モニタリングでは、モデルの動作とビジネス成果に関連する指標に焦点を当てるべきです。</p><p>D) データドリフトの検出 - これは極めて重要な指標です。本番環境のデータ分布が訓練時のデータから変化すると、モデルの性能が低下します。Amazon SageMaker Model Monitorでは、統計的手法を使用してデータドリフトを自動検出できます。</p><p>実践例：金融機関の不正検知システムでは、予測精度、誤検知率、レイテンシー、データドリフトなどを常時モニタリングしています。これにより、新たな不正パターンの出現や季節変動による影響を早期に検出し、モデルの再訓練や調整を行うことができます。</p><h5>なぜ他の選択肢が間違っているのか</h5><ul><li><strong>A) 予測精度の経時変化:</strong> バイアスを完全に除去することは現実的に不可能です。目標は可能な限り最小化することです。</li><li><strong>D) データドリフトの検出:</strong> 技術的対策だけでは不十分で、プロセス全体での継続的な取り組みが必要です。</li></ul>",
      "resources": []
    },
    {
      "id": "d4_q10",
      "type": "single",
      "text": "AWSでMLモデルのコスト最適化を行う方法として最も効果的なものはどれですか？",
      "choices": [
        {
          "label": "A",
          "text": "常に最大のインスタンスサイズを使用する"
        },
        {
          "label": "B",
          "text": "SageMakerのスポットインスタンスと自動スケーリングを活用する"
        },
        {
          "label": "C",
          "text": "モデルの更新を避ける"
        },
        {
          "label": "D",
          "text": "データの前処理を省略する"
        }
      ],
      "correct": [
        1
      ],
      "explanation": "<h5>詳細解説</h5><p>正解はB: SageMakerのスポットインスタンスと自動スケーリングを活用するです。</p><p>AWSでのMLモデルのコスト最適化は、ビジネスの持続可能性にとって重要です。SageMakerのスポットインスタンスと自動スケーリングの組み合わせは、コストを大幅に削減しながら、必要なパフォーマンスを維持できます。</p><h5>各選択肢の解説</h5><ul><li><strong>A) 常に最大のインスタンスサイズを使用する</strong> - これはコスト最適化の逆です。必要以上のリソースを使用することで、不必要なコストが発生します。適切なインスタンスサイズの選択は、コスト最適化の基本です。</li><li><strong>B) SageMakerのスポットインスタンスと自動スケーリングを活用する（正解）</strong> - このアプローチには以下の利点があります：<ul><li>スポットインスタンスは最大70%のコスト削減が可能</li><li>自動スケーリングにより、需要に応じてリソースを調整し、アイドルタイムのコストを削減</li><li>SageMaker Multi-Model Endpointsを使用して複数のモデルを一つのエンドポイントでホスト</li><li>SageMaker Serverless Inferenceを使用して、使用時のみ課金されるモデルをデプロイ</li></ul></li><li><strong>C) モデルの更新を避ける</strong> - これは短期的にはコストを節約できるかもしれませんが、長期的にはモデルの性能劣化によるビジネス損失のリスクがあります。定期的なモデルの更新は、精度を維持するために必要です。</li><li><strong>D) データの前処理を省略する</strong> - データの前処理はモデルの性能を向上させる重要なステップであり、これを省略するとモデルの精度が低下し、結果的により多くのリソースが必要になる可能性があります。</li></ul><h5>実践例</h5><p>あるスタートアップ企業では、SageMakerのスポットインスタンスをモデル訓練に使用し、推論にはSageMaker Serverless Inferenceを使用することで、月間のMLコストを60%削減しました。また、CloudWatchと連携した自動スケーリングを設定し、ピーク時のみリソースを増強することで、パフォーマンスを維持しながらコストを最適化しています。</p><h5>なぜ他の選択肢が間違っているのか</h5><ul><li><strong>A) 常に最大のインスタンスサイズを使用する:</strong> コスト最適化には適切なリソース選択が重要で、過剰なリソースは無駄になります。</li><li><strong>C) モデルの更新を避ける:</strong> この選択肢はコスト最適化に寄与しません。</li><li><strong>D) データの前処理を省略する:</strong> この選択肢はコスト最適化に寄与しません。</li></ul>",
      "resources": []
    }
  ]
}
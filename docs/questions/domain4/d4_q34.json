{
  "id": "d4_q34",
  "type": "single",
  "text": "MLパイプラインにおける「データ品質チェック」の実装として重要なものはどれですか？",
  "choices": [
    {
      "label": "A",
      "text": "チェックを省略して高速化"
    },
    {
      "label": "B",
      "text": "スキーマ検証、統計的検証、異常値検出の自動化"
    },
    {
      "label": "C",
      "text": "手動でのみチェック"
    },
    {
      "label": "D",
      "text": "エラーが出てから対処"
    }
  ],
  "correct": [
    1
  ],
  "explanation": "<h5>詳細解説</h5><p>正解はB: スキーマ検証、統計的検証、異常値検出の自動化です。</p><p>データ品質はMLモデルの性能を左右する最も重要な要素の一つです。自動化されたデータ品質チェックにより、問題を早期に発見し、モデルの信頼性を確保できます。</p><h5>各選択肢の解説</h5><p>A) チェックを省略して高速化 - これは短期的な時間節約に見えますが、不良データによるモデルの失敗は、はるかに大きなコストをもたらします。</p><h5>B) スキーマ検証、統計的検証、異常値検出の自動化（正解）- 包括的なデータ品質管理</h5><ul><li>スキーマ検証：</li><li>データ型の一致（数値、文字列、日付）</li><li>必須フィールドの存在確認</li><li>値の範囲チェック</li><li>参照整合性の確認</li><li>統計的検証：</li><li>分布の変化検出（KSテスト、χ²テスト）</li><li>平均・分散のモニタリング</li><li>相関関係の安定性</li><li>クラス不均衡の検出</li><li>異常値検出：</li><li>統計的手法（IQR、Zスコア）</li><li>機械学習ベース（Isolation Forest）</li><li>ドメイン知識に基づくルール</li><li>時系列異常検出</li><li>自動化の利点：</li><li>一貫性のある品質保証</li><li>早期問題発見</li><li>スケーラビリティ</li><li>監査証跡の自動生成</li></ul><p>C) 手動でのみチェック - 人的エラー、スケーラビリティの欠如、一貫性の欠如につながります。</p><p>D) エラーが出てから対処 - リアクティブなアプローチは、本番環境での障害につながり、ビジネスに損害を与えます。</p><h5>実践例：金融取引データのMLパイプライン</h5><h5>1. データ品質フレームワークの実装</h5><p>```python</p><h5>class DataQualityChecker</h5><h5>def __init__(self)</h5><p>self.schema_validator = SchemaValidator()</p><p>self.statistical_validator = StatisticalValidator()</p><p>self.anomaly_detector = AnomalyDetector()</p><h5>def validate(self, df)</h5><p># スキーマ検証</p><p>schema_results = self.schema_validator.check(df)</p><p># 統計的検証</p><p>stats_results = self.statistical_validator.check(df)</p><p># 異常値検出</p><p>anomaly_results = self.anomaly_detector.check(df)</p><p>return ValidationReport(schema_results,</p><p>stats_results,</p><p>anomaly_results)</p><p>```</p><h5>2. 自動化されたチェック項目</h5><ul><li>完全性チェック：</li><li>NULL値の割合</li><li>重複レコード</li><li>参照整合性</li><li>一貫性チェック：</li><li>日付の論理性（未来日付など）</li><li>金額の妥当性</li><li>カテゴリ値の妥当性</li><li>正確性チェック：</li><li>外部ソースとの照合</li><li>ビジネスルールの適用</li><li>計算フィールドの検証</li></ul><h5>3. Great Expectationsの活用</h5><p>```python</p><p># 期待値の定義</p><p>batch.expect_column_values_to_not_be_null('customer_id')</p><p>batch.expect_column_values_to_be_between('age', 18, 120)</p><p>batch.expect_column_mean_to_be_between('transaction_amount',</p><p>100, 10000)</p><p>```</p><h5>4. パイプライン統合</h5><ul><li>Apache Airflowでのオーケストレーション</li><li>品質チェックのDAGノード化</li><li>失敗時の自動リトライとアラート</li></ul><h5>5. モニタリングダッシュボード</h5><ul><li>データ品質スコアの可視化</li><li>トレンド分析</li><li>アラートとインシデント管理</li></ul><h5>成果</h5><ul><li>データ品質起因の本番障害：95%削減</li><li>モデル再訓練の必要性：60%削減</li><li>データ準備時間：70%短縮</li><li>規制監査合格率：100%</li></ul><h5>ベストプラクティス</h5><ul><li>データ品質SLAの設定</li><li>段階的な検証（軽量→詳細）</li><li>品質メトリクスの継続的改善</li><li>ステークホルダーへの定期報告</li></ul><h5>なぜ他の選択肢が間違っているのか</h5><ul><li><strong>A) チェックを省略して高速化:</strong> ドメイン適応は重要で、事前学習モデルをそのまま使用すると性能が低下する可能性があります。</li><li><strong>C) 手動でのみチェック:</strong> 転移学習でも一定量のターゲットドメインデータが必要で、データフリーではありません。</li><li><strong>D) エラーが出てから対処:</strong> 浅い層も重要な特徴を学習しており、深い層だけの転移では不十分な場合があります。</li></ul>",
  "resources": []
}